{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlackHole3344/FineTune/blob/main/data_creation_tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jGReZlvDmm6l",
        "outputId": "c71c971b-0b28-42b3-a44d-cf64ac95e51c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqS2LrX5QYyj"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HSkfzcRFmuOR",
        "outputId": "5b5cec22-ef28-4dad-cdcb-0e9fef1ad4dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-groq in /usr/local/lib/python3.11/dist-packages (0.3.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-groq) (0.12.16.post1)\n",
            "Requirement already satisfied: llama-index-llms-openai-like<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-groq) (0.3.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2024.9.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.17.2)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.3.18)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (4.48.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.18.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (1.61.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.5.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-llms-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ddzw2Nh7nQgA",
        "outputId": "607111cf-82e3-41eb-ea2f-77891b350536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.16)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.16 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.16.post1)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.18)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.4)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.61.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (2024.9.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.11)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.2.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi<2025.0.0,>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.8->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2024.12.14)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.16->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePQJRyORoOHp"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.groq import Groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry6I7dG_oRGX"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GROQ = userdata.get('GROQ')\n",
        "llm = Groq(model=\"deepseek-r1-distill-llama-70b\", api_key=GROQ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wYvo5V6xyKeS",
        "outputId": "8ac0c371-8dbe-4697-e54d-592969aeccc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletionResponse(text=\"<think>\\nOkay, so I'm trying to learn about ChromaDB, which is a vector database. I remember that vector databases are used for similarity searches, especially with embeddings from machine learning models. But I'm not entirely sure how they work or what makes ChromaDB different from others.\\n\\nFirst, I think I should understand what a vector database is. From what I know, traditional databases store structured data, but vector databases store vectors, which are like arrays of numbers. These vectors can represent complex data, like images or text, after being processed by a model. So, when you have a query, you can find similar items by comparing vectors.\\n\\nChromaDB is one of these vector databases. I remember it's open-source, which is great because it's accessible for learning and projects. I think it's built in Go, which is a language known for its efficiency and concurrency support. That might mean ChromaDB is fast and can handle a lot of requests at once.\\n\\nI'm not sure about the key features. I think it supports approximate nearest neighbor (ANN) search, which is important for finding similar vectors without having to check every single one, which would be too slow. But how does it handle this? Maybe it uses some kind of indexing or quantization. I've heard of techniques like HNSW or PQ, so perhaps ChromaDB uses one of those.\\n\\nScalability is another aspect. Vector databases need to handle large amounts of data and scale horizontally. I think ChromaDB might use a distributed architecture, where data is split across multiple nodes. This would allow it to handle more data and more queries as the system grows. But I'm not sure how it manages consistency or partitions the data.\\n\\nIngesting data is another point. I suppose you can add vectors in various formats, maybe through an API or some import tool. I'm not sure if it supports different data formats like CSV or direct API calls. Also, how does it handle metadata? Storing additional information alongside vectors is useful for filtering or additional queries.\\n\\nQuerying capabilities are crucial. Besides ANN search, maybe it supports range queries or filtering based on metadata. I'm not sure if it has a built-in way to handle complex queries or if it's mainly focused on similarity searches.\\n\\nPerformance-wise, I think ChromaDB is optimized for speed. Since it's written in Go, it might have low latency and high throughput. But how does it compare to other databases like FAISS or Milvus? I'm not sure about the benchmarks, but I think ChromaDB is known for being lightweight and easy to set up.\\n\\nIntegration with machine learning workflows is another feature. It probably works well with popular libraries like TensorFlow or PyTorch. Maybe there are client libraries for different languages, allowing easy integration into ML pipelines. I'm not sure how extensive the support is, though.\\n\\nUse cases would include applications like image or video search, recommendation systems, natural language processing, and fraud detection. For example, in image search, each image is converted into a vector, and then you can search for similar images. In recommendation systems, user or item embeddings can be stored to find similar users or items.\\n\\nI'm also thinking about how ChromaDB handles data management. Does it support versioning or backups? How about data replication for high availability? These are important for production environments but might not be as crucial for small projects.\\n\\nSecurity is another consideration. I'm not sure if ChromaDB has built-in security features like authentication or encryption. It might rely on external systems for that, which is common in databases.\\n\\nThe community and documentation are important too. Since it's open-source, a strong community can mean more support and resources. Good documentation helps in getting started and troubleshooting issues. I think ChromaDB has decent documentation, but I'm not certain.\\n\\nComparing ChromaDB to other vector databases, I know there's FAISS from Facebook, which is also open-source and highly optimized. Milvus is another one that's popular and scalable. Annoy is from Spotify and is known for its simplicity. So where does ChromaDB fit? It might be more lightweight and easier to use compared to Milvus, but maybe not as highly scalable. Or perhaps it's designed for specific use cases where ease of use is more important.\\n\\nI'm also wondering about the storage backend. Does ChromaDB use a disk-based storage or is it in-memory? In-memory would be faster but might not handle very large datasets. Disk-based storage allows for persistence but could be slower. Maybe it supports both, or maybe it's designed with a specific storage approach in mind.\\n\\nAnother thought is about the API. I think ChromaDB has a RESTful API, which makes it easy to interact with from different programming languages. There might also be SDKs for languages like Python or Java, which would make integration into applications smoother.\\n\\nI'm curious about the indexing methods. HNSW is a popular graph-based method for ANN search. PQ is product quantization, which is good for reducing memory usage. Maybe ChromaDB supports multiple indexing techniques, allowing users to choose based on their needs.\\n\\nIn terms of use cases, I can think of a few examples. For instance, in e-commerce, using ChromaDB to power a recommendation engine where products are represented as vectors. Or in healthcare, analyzing medical images by converting them into vectors and searching for similar cases.\\n\\nI'm also thinking about how to get started with ChromaDB. Probably, you can install it via Docker, which makes setup straightforward. Then, you can use a client library to insert vectors and perform queries. There might be tutorials or examples on their GitHub page.\\n\\nI'm not sure about the limitations. Maybe it's not as scalable as some other databases, or it might lack some advanced features. But for many use cases, especially smaller ones, it might be sufficient.\\n\\nIn summary, ChromaDB seems like a solid choice for vector search needs, especially if you value ease of use and a lightweight setup. It's open-source, efficient, and integrates well with ML workflows. But I should look into specific features, benchmarks, and community support to get a clearer picture.\\n</think>\\n\\nChromaDB is an open-source vector database designed for efficient similarity searches, particularly with embeddings from machine learning models. Here's a detailed overview based on the thought process:\\n\\n### Key Features:\\n1. **Vector Storage and Search**: ChromaDB stores vectors, which are arrays of numbers representing complex data like images or text. It supports approximate nearest neighbor (ANN) search for finding similar vectors efficiently.\\n\\n2. **Efficiency and Scalability**: Built in Go, ChromaDB is known for its efficiency and ability to handle high concurrency. It uses a distributed architecture to scale horizontally, managing large datasets and high query loads.\\n\\n3. **Ingesting Data**: Supports various data formats and offers APIs for easy data ingestion. It also handles metadata for additional filtering and querying capabilities.\\n\\n4. **Querying Capabilities**: Beyond ANN search, ChromaDB may support range queries and filtering, enhancing its versatility in different applications.\\n\\n5. **Performance**: Optimized for low latency and high throughput, making it suitable for real-time applications. It's lightweight and easy to set up compared to other databases.\\n\\n6. **Integration with ML Workflows**: Works seamlessly with libraries like TensorFlow and PyTorch, with client libraries available for various programming languages.\\n\\n### Use Cases:\\n- **Image and Video Search**: Converts media into vectors for similarity searches.\\n- **Recommendation Systems**: Uses user or item embeddings to find similar items or users.\\n- **Natural Language Processing (NLP)**: Manages text embeddings for semantic searches.\\n- **Fraud Detection**: Analyzes patterns in transaction data for anomaly detection.\\n\\n### Technical Aspects:\\n- **Indexing Methods**: Likely supports techniques like HNSW and PQ for efficient ANN searches.\\n- **Storage**: May use disk-based storage for persistence, with possible support for in-memory operations for speed.\\n- **API and SDKs**: Offers a RESTful API and SDKs for easy integration into applications.\\n\\n### Community and Documentation:\\n- As an open-source project, ChromaDB benefits from community contributions and support. It has decent documentation, aiding in setup and troubleshooting.\\n\\n### Comparison with Other Databases:\\nChromaDB is positioned as a lightweight and user-friendly option, potentially less scalable than Milvus but easier to use than FAISS or Annoy.\\n\\n### Limitations:\\n- May not be as scalable as some competitors.\\n- Might lack certain advanced features available in more mature databases.\\n\\n### Getting Started:\\n- Easily installable via Docker, with tutorials and examples available on its GitHub page.\\n\\nIn summary, ChromaDB is a robust choice for vector search, offering efficiency, ease of use, and good integration with ML workflows, making it suitable for various applications, especially where setup simplicity is valued.\", additional_kwargs={}, raw=ChatCompletion(id='chatcmpl-aadac3af-18f4-4ab1-a049-ecaff2e85b34', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"<think>\\nOkay, so I'm trying to learn about ChromaDB, which is a vector database. I remember that vector databases are used for similarity searches, especially with embeddings from machine learning models. But I'm not entirely sure how they work or what makes ChromaDB different from others.\\n\\nFirst, I think I should understand what a vector database is. From what I know, traditional databases store structured data, but vector databases store vectors, which are like arrays of numbers. These vectors can represent complex data, like images or text, after being processed by a model. So, when you have a query, you can find similar items by comparing vectors.\\n\\nChromaDB is one of these vector databases. I remember it's open-source, which is great because it's accessible for learning and projects. I think it's built in Go, which is a language known for its efficiency and concurrency support. That might mean ChromaDB is fast and can handle a lot of requests at once.\\n\\nI'm not sure about the key features. I think it supports approximate nearest neighbor (ANN) search, which is important for finding similar vectors without having to check every single one, which would be too slow. But how does it handle this? Maybe it uses some kind of indexing or quantization. I've heard of techniques like HNSW or PQ, so perhaps ChromaDB uses one of those.\\n\\nScalability is another aspect. Vector databases need to handle large amounts of data and scale horizontally. I think ChromaDB might use a distributed architecture, where data is split across multiple nodes. This would allow it to handle more data and more queries as the system grows. But I'm not sure how it manages consistency or partitions the data.\\n\\nIngesting data is another point. I suppose you can add vectors in various formats, maybe through an API or some import tool. I'm not sure if it supports different data formats like CSV or direct API calls. Also, how does it handle metadata? Storing additional information alongside vectors is useful for filtering or additional queries.\\n\\nQuerying capabilities are crucial. Besides ANN search, maybe it supports range queries or filtering based on metadata. I'm not sure if it has a built-in way to handle complex queries or if it's mainly focused on similarity searches.\\n\\nPerformance-wise, I think ChromaDB is optimized for speed. Since it's written in Go, it might have low latency and high throughput. But how does it compare to other databases like FAISS or Milvus? I'm not sure about the benchmarks, but I think ChromaDB is known for being lightweight and easy to set up.\\n\\nIntegration with machine learning workflows is another feature. It probably works well with popular libraries like TensorFlow or PyTorch. Maybe there are client libraries for different languages, allowing easy integration into ML pipelines. I'm not sure how extensive the support is, though.\\n\\nUse cases would include applications like image or video search, recommendation systems, natural language processing, and fraud detection. For example, in image search, each image is converted into a vector, and then you can search for similar images. In recommendation systems, user or item embeddings can be stored to find similar users or items.\\n\\nI'm also thinking about how ChromaDB handles data management. Does it support versioning or backups? How about data replication for high availability? These are important for production environments but might not be as crucial for small projects.\\n\\nSecurity is another consideration. I'm not sure if ChromaDB has built-in security features like authentication or encryption. It might rely on external systems for that, which is common in databases.\\n\\nThe community and documentation are important too. Since it's open-source, a strong community can mean more support and resources. Good documentation helps in getting started and troubleshooting issues. I think ChromaDB has decent documentation, but I'm not certain.\\n\\nComparing ChromaDB to other vector databases, I know there's FAISS from Facebook, which is also open-source and highly optimized. Milvus is another one that's popular and scalable. Annoy is from Spotify and is known for its simplicity. So where does ChromaDB fit? It might be more lightweight and easier to use compared to Milvus, but maybe not as highly scalable. Or perhaps it's designed for specific use cases where ease of use is more important.\\n\\nI'm also wondering about the storage backend. Does ChromaDB use a disk-based storage or is it in-memory? In-memory would be faster but might not handle very large datasets. Disk-based storage allows for persistence but could be slower. Maybe it supports both, or maybe it's designed with a specific storage approach in mind.\\n\\nAnother thought is about the API. I think ChromaDB has a RESTful API, which makes it easy to interact with from different programming languages. There might also be SDKs for languages like Python or Java, which would make integration into applications smoother.\\n\\nI'm curious about the indexing methods. HNSW is a popular graph-based method for ANN search. PQ is product quantization, which is good for reducing memory usage. Maybe ChromaDB supports multiple indexing techniques, allowing users to choose based on their needs.\\n\\nIn terms of use cases, I can think of a few examples. For instance, in e-commerce, using ChromaDB to power a recommendation engine where products are represented as vectors. Or in healthcare, analyzing medical images by converting them into vectors and searching for similar cases.\\n\\nI'm also thinking about how to get started with ChromaDB. Probably, you can install it via Docker, which makes setup straightforward. Then, you can use a client library to insert vectors and perform queries. There might be tutorials or examples on their GitHub page.\\n\\nI'm not sure about the limitations. Maybe it's not as scalable as some other databases, or it might lack some advanced features. But for many use cases, especially smaller ones, it might be sufficient.\\n\\nIn summary, ChromaDB seems like a solid choice for vector search needs, especially if you value ease of use and a lightweight setup. It's open-source, efficient, and integrates well with ML workflows. But I should look into specific features, benchmarks, and community support to get a clearer picture.\\n</think>\\n\\nChromaDB is an open-source vector database designed for efficient similarity searches, particularly with embeddings from machine learning models. Here's a detailed overview based on the thought process:\\n\\n### Key Features:\\n1. **Vector Storage and Search**: ChromaDB stores vectors, which are arrays of numbers representing complex data like images or text. It supports approximate nearest neighbor (ANN) search for finding similar vectors efficiently.\\n\\n2. **Efficiency and Scalability**: Built in Go, ChromaDB is known for its efficiency and ability to handle high concurrency. It uses a distributed architecture to scale horizontally, managing large datasets and high query loads.\\n\\n3. **Ingesting Data**: Supports various data formats and offers APIs for easy data ingestion. It also handles metadata for additional filtering and querying capabilities.\\n\\n4. **Querying Capabilities**: Beyond ANN search, ChromaDB may support range queries and filtering, enhancing its versatility in different applications.\\n\\n5. **Performance**: Optimized for low latency and high throughput, making it suitable for real-time applications. It's lightweight and easy to set up compared to other databases.\\n\\n6. **Integration with ML Workflows**: Works seamlessly with libraries like TensorFlow and PyTorch, with client libraries available for various programming languages.\\n\\n### Use Cases:\\n- **Image and Video Search**: Converts media into vectors for similarity searches.\\n- **Recommendation Systems**: Uses user or item embeddings to find similar items or users.\\n- **Natural Language Processing (NLP)**: Manages text embeddings for semantic searches.\\n- **Fraud Detection**: Analyzes patterns in transaction data for anomaly detection.\\n\\n### Technical Aspects:\\n- **Indexing Methods**: Likely supports techniques like HNSW and PQ for efficient ANN searches.\\n- **Storage**: May use disk-based storage for persistence, with possible support for in-memory operations for speed.\\n- **API and SDKs**: Offers a RESTful API and SDKs for easy integration into applications.\\n\\n### Community and Documentation:\\n- As an open-source project, ChromaDB benefits from community contributions and support. It has decent documentation, aiding in setup and troubleshooting.\\n\\n### Comparison with Other Databases:\\nChromaDB is positioned as a lightweight and user-friendly option, potentially less scalable than Milvus but easier to use than FAISS or Annoy.\\n\\n### Limitations:\\n- May not be as scalable as some competitors.\\n- Might lack certain advanced features available in more mature databases.\\n\\n### Getting Started:\\n- Easily installable via Docker, with tutorials and examples available on its GitHub page.\\n\\nIn summary, ChromaDB is a robust choice for vector search, offering efficiency, ease of use, and good integration with ML workflows, making it suitable for various applications, especially where setup simplicity is valued.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738921288, model='deepseek-r1-distill-llama-70b', object='chat.completion', service_tier=None, system_fingerprint='fp_af2982c95d', usage=CompletionUsage(completion_tokens=1813, prompt_tokens=11, total_tokens=1824, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.13605252499999998, prompt_time=0.003665673, completion_time=6.592727273, total_time=6.596392946), x_groq={'id': 'req_01jkfwj868fh2s274dtga9wqha'}), logprobs=None, delta=None)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.complete(\"tell me about chormadb vector database\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRurEF3tQrwX"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict\n",
        "import re\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KpSnG0bQhyP"
      },
      "outputs": [],
      "source": [
        "class DatasetHandler :\n",
        "  def __init__(self , dataset_name : str , path_to_save : str = \"local_dataset\" , split : int = 500) :\n",
        "    self.dataset_name = dataset_name\n",
        "    self.path_to_save = path_to_save\n",
        "    os.makedirs(self.path_to_save , exist_ok=True)\n",
        "    self.split = split\n",
        "    self.dataset = load_dataset(self.dataset_name , split = f\"train[:{self.split}]\")\n",
        "\n",
        "  def LoadDataset(self):\n",
        "    try :\n",
        "        local_data = {}\n",
        "\n",
        "        for data in self.dataset:\n",
        "          for key , value in data.items():\n",
        "            if key not in local_data:\n",
        "              local_data[key] = []\n",
        "            local_data[key].append(value)\n",
        "\n",
        "        path_json = os.path.join(self.path_to_save , \"dataset.json\")\n",
        "        print(path_json)\n",
        "        with open(path_json , \"w\" , encoding = \"utf-8\") as f :\n",
        "          json.dump(local_data , f)\n",
        "        print(f\"Dataset saved at {path_json}\")\n",
        "        return True\n",
        "    except Exception as e :\n",
        "      print(\"error  :\" , e )\n",
        "      return False\n",
        "\n",
        "  def load_local_dataset(self):\n",
        "    try :\n",
        "      path_json = os.path.join(self.path_to_save , \"dataset.json\")\n",
        "      print(path_json)\n",
        "      with open(path_json , \"r\") as f :\n",
        "        dataset = json.load(f)\n",
        "      return dataset\n",
        "    except Exception as e :\n",
        "      print(\"error : \" , e)\n",
        "      return None\n",
        "\n",
        "\n",
        "  def get_dataset(self) :\n",
        "    return self.dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "f0674d524eb94868aca3ef1bfa97284c",
            "60fc1f72f9d84934b9ad7a1300837626",
            "8cd4315cb8924e5db6f45697f3d589d0",
            "c1dbdc045f874d71a6bdb7f9524e8fa3",
            "ef36abd2b2b74ba59dd3c857fadd5cdc",
            "3a6875acb324409e9593eb3f2974f36b",
            "69870aef330647c98072c185d6e2c9f6",
            "2866dc3ade624e0faffb22581c88ac73",
            "5708368d24e54c798f05f68873055ed1",
            "4ee19facb6a042109ee81d7c0a13cf93",
            "1096e13b86804a9cafb3afa4342d08d0",
            "9d119e2bc08f4373a299468742dce172",
            "28a02dd3df3946ee830d8dc4540c5fc8",
            "1a3b3b3ce4ef4d20b2eb587320184dbb",
            "17d2772d86f94695b94e29a0274e9826",
            "1ca01acd7bdf4586bc0614a67b936847",
            "537e573bd62e4b7b96853370d60ec48a",
            "698dbcb270b44d4cae56ee05ef6d61cf",
            "7877f39b96c141fbb2aea6b6e724d515",
            "86908cb003204c058873d3e5e6e7ef29",
            "474aecf520484bbab22ce1e5288bf993",
            "8de01b7b56904392a1fe139fffcc2db4",
            "8cb8be7bc5a94c58bc53c453475dbdb1",
            "922bec68502542d19fdb07c354013beb",
            "f8a5f63d905b4a58b6e188a70746a6a9",
            "3540853c6b5b4e118354c3c0586b9516",
            "2199418ec51b4164923094c33dd65a02",
            "0e6cdd4b54344d20ba00e1f7866b7c3d",
            "c3cfc585943e4169824477dc85e256e3",
            "f230f44def7b4f87bfa18d0f81c86378",
            "b4231a0c0d3f473e97ac3f762a3030b0",
            "3562c0a156564caba3213b2aa2ab26ca",
            "407a23a07d984ee0b4619ec865750ce2",
            "141464a4ff0c4f3aa76eae1fdddb46a7",
            "fce44f14cb734ecca3baca4154ae3398",
            "18b27548ca0c447c88e7b62e7979d7e1",
            "556224c796304c4f802617dbf8b2c8a0",
            "4cd5441764b64d60b1d4301ce029f91a",
            "fd0dfc0b41a14dd285f8d2637358c72f",
            "e1e05db9f46d41bf93d049e974ed172a",
            "4dbf105617be4a9f92f74ac764ee5f5d",
            "537eea5ab7cc4e949a1a020b3d0ed94f",
            "1a8cdb06435d4e3ab9e45dceb485d931",
            "93ecf2676a1d496bb2d2cecc13f4a570",
            "3f4ec2cdc7284ab6b300431bd9dd01c4",
            "8ea5d709311b4a99b15c1b294ebb2305",
            "8dded18238864ba1b611ff50f0d6bdfe",
            "8eb6986493cf401f8c8166e535260cca",
            "da3ed1c2626649308cf19091b5f50088",
            "34ee8aff4b20423abc89f8352683784a",
            "eb88c03a22fa4798944d05a5d9995fe4",
            "40edf3ecafba4fe2b55e409b2009d517",
            "3265ff5748ab4d728345c730118f3067",
            "9fbad0ce5e3745b7a9915b2ac6dd0781",
            "c08dfcb9e29343ea8c920e437d731042",
            "ab613d64c0ff4ac69b89084aa9b9704a",
            "15cdda31143f4c64bd1c623e18d2ed58",
            "28bd01a14c5d4a66a0c5e27d0b3d0af9",
            "3ac1a64155ec4dc38b1ae8be408167e2",
            "6820b7a53f46430a87b4d8d9c6abddb9",
            "6d74fc0962c04157b6001e0ae7f76161",
            "f63122cd911041e6a970f58f6cd1c458",
            "207363544cb946bfa246d7d890f6fa27",
            "ce2e0c8864524dbc992b79b43d7c6c0f",
            "4bf0fa8aab4143f6ae7dc3dd7a6ac620",
            "f9b4dc7816854c299d7360a4f518b8b7",
            "c9dac3c57879433fa097c31106226ed4",
            "2caa1836bc2e42f68942d12311878406",
            "5c20c5c578f34cc096bd83d80669e7fb",
            "4920ffc9665d4058b821139bd4e3ec03",
            "10f94446b9da4c2aaa1ace9e6d55c4da",
            "e43f6d5d8e8243f0a430c5773b7a3091",
            "9900435b269d41bb905537fd79968856",
            "a89a5133a99a410aa9a5f8208d01d006",
            "65e44c2bed43456bb244b30f9e14d089",
            "a3501a4369824fe79efd062606012d87",
            "a4d058f58dfe4f9cb08f023429944793",
            "48c7318c932f427e87b3cb73e2e6d192",
            "82214918f99945e9bbbcf963c30548f5",
            "d9fc91cc653141288bc9d2e0b9cddc03",
            "20706b6f758447a3ae9bcac6ba0f496d",
            "1a29a7e0a4ea4aeca6737b1d4e63e5a5",
            "8a56c61300814b2b880d738dd0454ebc",
            "9ac08ddb7e514a68b2a1bf948d261ed9",
            "a9f9906f5e4c4775ab9b9c814a6a4423",
            "fd528336eeb2496da19d9de49020bb9e",
            "44f0ee538e7b43f9a9ac0211ce7a94ec",
            "63f995713df140f3a32a257bac42a98f"
          ]
        },
        "id": "SYORUbL6zRzK",
        "outputId": "e60b9f3d-97ad-4bc5-fcd5-900f7dd5428e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/324 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0674d524eb94868aca3ef1bfa97284c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00006.parquet:   0%|          | 0.00/261M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d119e2bc08f4373a299468742dce172"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00001-of-00006.parquet:   0%|          | 0.00/253M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cb8be7bc5a94c58bc53c453475dbdb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00002-of-00006.parquet:   0%|          | 0.00/251M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "141464a4ff0c4f3aa76eae1fdddb46a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00003-of-00006.parquet:   0%|          | 0.00/252M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f4ec2cdc7284ab6b300431bd9dd01c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00004-of-00006.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab613d64c0ff4ac69b89084aa9b9704a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00005-of-00006.parquet:   0%|          | 0.00/251M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9dac3c57879433fa097c31106226ed4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/68325 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48c7318c932f427e87b3cb73e2e6d192"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RedHenLabs_eng/dataset.json\n",
            "Dataset saved at RedHenLabs_eng/dataset.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def to_lower(texts) :\n",
        "  return texts.lower()\n",
        "\n",
        "\n",
        "dataset = DatasetHandler(\"RedHenLabs/eng-context-metadata\" , path_to_save=\"RedHenLabs_eng\" ,  split = 500)\n",
        "dataset.LoadDataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdrJou3SlQKo",
        "outputId": "3d071b4b-2182-447c-bcab-7c3dad752547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RedHenLabs_eng/dataset.json\n"
          ]
        }
      ],
      "source": [
        "json_data = dataset.load_local_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "M6aaM04WuoPD",
        "outputId": "34e21ab5-90e9-4f82-9752-b53782ee19a8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'>>> A LOT OF YOU MAY BE ASKING.WHAT THIS NEW E-MAIL STORY IS.ABOUT..>> THANK YOU, HUMA..THANK YOU, ANTHONY WEINER..>> THERE IS NO CASE..>> TEASE ARE NOT THE HALLMARKS.OF A RESPONSIBLE INVESTIGATION..>> I HAVE TO GIVE THE FBI.CREDIT..IT TOOK A LOT OF GUTS..>> ONE U.S. SENATOR\\'S SHOCKING.COMMENTS CAUGHT ON TAPE..>> THIS IS ONE OF THOSE ME OR.BREAK MOMENTS..>> TO ALL AMERICANS, I SAY IT IS.TIME FOR REAL LEADERSHIP..>> IT TRULY IS IN YOUR HANDS..>> THIS IS \"NEW DAY\" WITH CHRIS.CUOMO AND ALISYN CAMEROTA..>> GOOD MORNING..WELCOME TO YOUR NEW DAY..A BLATANT DOUBLE STANDARD..THAT\\'S WHAT CLINTON CALLS THE.FBI\\'S SURPRISE ANNOUNCEMENT OF.THAT PROBE INTO HUMA ABEDIN\\'S.E-MAILS..CLINTON SAYS, QUOTE, THERE\\'S NO.CASE HERE..>> NEED MORE CONTROVERSY?.HOW ABOUT THIS..DONALD TRUMP\\'S CAMPAIGN IS.FACING NEW QUESTIONS THIS.MORNING ABOUT WHETHER HE CHEATED.TO AVOID PAYING TENS OF MILLIONS.OF DOLLARS IN FEDERAL TAXES OVER.NEARLY TWO DECADES..ALSO, THERE ARE MULTIPLE AND.UNCORROBORATED REPORTS ABOUT HIS.CAMPAIGN\\'S POTENTIAL LINKS TO.RUSSIA..THIS ALL MATTERS MORE BECAUSE OF.WHERE WE ARE, SEVEN DAYS OUT.FROM THE ELECTION..WE\\'VE GOT IT ALL COVERED FOR.YOU..LET\\'S BEGIN WITH CNN JUSTICE.CORRESPONDENT EVAN PEREZ LIVE IN.WASHINGTON..EVAN?.>> Reporter: GOOD MORNING,.CHRIS..THE BIG QUESTION TODAY REMAINS,.WILL THE FBI BE ABLE TO PROVIDE.MORE INFORMATION ABOUT WHAT ITS.INVESTIGATION INTO HUMA ABEDIN\\'S.RECENT HE DISCOVERED E-MAILS ARE.SHOWING..FBI DIRECTOR JAMES COMEY HAS.TOLD OFFICIALS AT THIS POINT HE.HAS NO PLAN TO PROVIDE PARTIAL.UPDATE, AND IT\\'S UNLIKELY THAT.HIS INVESTIGATORS CAN COMPLETE.THEIR WORK BY ELECTION DAY..A TEAM OF INVESTIGATORS HAS.BEGUN THE WORK OF DIGGING.THROUGH THESE THOUSANDS OF.E-MAILS, WHICH WERE FOUND ON THE.COMPUTER BELONGING TO ABEDIN\\'S.HUSBAND, FORMER CONGRESSMAN.ANTHONY WEINER..ABEDIN\\'S ATTORNEY SAYS SHE HAS.NO IDEA HOW HER E-MAILS WERE ON.THE COMPUTER AT THIS POINT..THE FBI INVESTIGATORS ARE STILL.TRYING TO FIGURE THAT OUT..THAT\\'S WHAT THE FBI COMPUTER.FORENSICS EXPERTS ARE TRYING TO.DO..COMEY\\'S BEEN UNDER ATTACK,.INCLUDING FROM ALL THREE MOST.RECENT ATTORNEYS GENERAL UNDER.THE BUSH AND OBAMA.ADMINISTRATIONS..ALL THREE FIND FAULT WITH.COMEY\\'S HANDLING OF THE CLINTON.INVESTIGATION AND PARTICULARLY.FOR THE PUBLICLY COMMENTING ON.THE LATEST E-MAIL DISCOVERY JUST.DAYS BEFORE THE ELECTION..COMEY\\'S CURRENT BOSS, ATTORNEY.GENERAL LORETTA LYNCH, CHECKED.IN ON COMEY YESTERDAY TO SEE HOW.HE WAS DOING..LYNCH WAS OPPOSED TO COMEY.SENDING HIS LETTER TO CONGRESS.ON FRIDAY, BUT WE\\'RE TOLD THE.CONVERSATIONS YESTERDAY WERE A.FRIENDLY CHAT BETWEEN TWO.OFFICIALS UNDER GREAT SCRUTINY.OVER THIS CLINTON INVESTIGATION..ALISYN?.>> EVAN, THANKS SO MUCH FOR ALL.OF YOUR REPORTING..THE CLINTON CAMPAIGN IS GOING.AFTER THE FBI CHIEF FOR WHAT.THEY CALL, QUOTE, A BLATANT.DOUBLE STANDARD..A NEW REPORT HAS DONALD TRUMP\\'S.TAXES BACK IN THE HEADLINES..PHIL MATTINGLY HAS IT ALL LIVE.FROM CHAPPAQUA, NEW YORK..>> Reporter: GOOD MORNING..THERE\\'S NO QUESTION ON FRIDAY.WHEN ALL OF THIS NEWS BROKE, THE.CLINTON CAMPAIGN WAS RATTLED..THEY WERE SHOCKED..THEY HAD NO IDEA THIS WAS.COMING..BY THE END OF THE WEEKEND AND.INTO MONDAY, IT BECAME VERY.CLEAR THEIR STRATEGY TO ESCALATE.THEIR ATTACKS ON THE FBI AND THE.FBI DIRECTOR, AND ALISYN,.DOESN\\'T LOOK LIKE THAT\\'S GOING.TO SLOW DOWN ANY TIME SOON..>> THERE IS NO CASE HERE..>> Reporter: HILLARY CLINTON AND.HER CAMPAIGN FIRING BACK AT FBI.DIRECTOR JAMES COMEY..SLAMMING HIS DECISION TO NOTIFY.CONGRESS OF A NEW INVESTIGATION.INTO THOUSANDS OF E-MAILS FOUND.ON A COMPUTER BELONGING TO THE.ESTRANGED HUSBAND OF A TOP.CLINTON AIDE, HUMA ABEDIN..CLINTON\\'S CAMPAIGN TURNING THE.TABLES ON COMEY..>> IT\\'S IMPOSSIBLE TO VIEW THIS.AS ANYTHING LESS THAN A BLATANT.DOUBLE STANDARD..>> Reporter: SEIZING ON REPORTS.THAT COMEY REFUSED TO PUBLICLY.COMMENT ON POTENTIAL TIES.BETWEEN DONALD TRUMP\\'S CAMPAIGN.AND RUSSIA..ON SUNDAY, SENATE MINORITY.LEADER HARRY REID ACCUSED COMEY.OF SITTING ON EXPLOSIVE.INFORMATION, TRUMP\\'S RUSSIA.CONNECTIONS, WITHOUT OFFERING.PROOF..CNN CANNOT CORROBORATE ANY OF.THESE REPORTS..U.S. OFFICIALS DO TELL CNN THAT.RUSSIA IS BEHIND HACKS THAT.COULD POTENTIALLY INFLUENCE THE.U.S. ELECTION..MEANWHILE, TRUMP IS CAPITALIZING.ON COMEY\\'S NEW E-MAIL PROBE..>> IT TOOK GUTS FOR DIRECTOR.COMEY TO MAKE THE MOVE THAT HE.MADE IN LIGHT OF THE KIND OF.OPPOSITION HE HAD..>> Reporter: COMEY HAS ONLY SAID.THE E-MAILS FOUND ON DISGRACED.CONGRESSMAN ANTHONY WEINER\\'S.COMPUTER, QUOTE, APPEAR TO BE.PERTINENT TO THE NOW-CLOSED.CLINTON PRIVATE SERVER.INVESTIGATION..>> WE CAN BE SURE THAT WHAT IS.IN THOSE E-MAILS IS ABSOLUTELY.DEVASTATING..I THINK WE\\'RE GOING TO FIND OUT,.BY THE WAY..FOR THE FIRST TIME..THANK YOU, HUMA..THANK YOU, ANTHONY WEINER..>> Reporter: ABEDIN\\'S ATTORNEY.RESPONDING, SAYING IN A.STATEMENT, QUOTE, FROM THE.BEGINNING MS. ABEDIN HAS.COMPLIED FULLY AND VOLUNTARILY.WITH STATE DEPARTMENT AND LAW.ENFORCEMENT REQUESTS AND.REITERATED ABEDIN ONLY LEARNED.OF THE E-MAILS ON WEINER\\'S.COMPUTER FRIDAY FROM THE PRESS..CLINTON CONTINUING TO APOLOGIZE.FOR HER PRIVATE E-MAIL SERVER.BUT ISSUING A CHALLENGE TO.INVESTIGATORS..>> I\\'M NOT MAKING EXCUSES..I\\'VE SAID IT WAS A MISTAKE AND I.REGRET IT..BY ALL MEANS, THEY SHOULD LOOK.AT THEM..AND I\\'M SURE THEY WILL REACH THE.SAME CONCLUSION THEY DID WHEN.THEY LOOKED AT MY E-MAILS FOR.THE LAST YEAR..>> Reporter: ALL OF THIS AS \"THE.NEW YORK TIMES\" OBTAINS.DOCUMENTS THAT THEY SAY SHOW.TRUMP POTENTIALLY ESCAPED TENS.OF MILLIONS OF DOLLARS IN.FEDERAL PERSONAL INCOME TAXES IN.THE 1990s BY USING A TAX.AVOIDANCE MANEUVER LATER.OUTLAWED BY CONGRESS..TRUMP\\'S CAMPAIGN RESPONDING TO.THE REPORT IN A STATEMENT.SAYING, QUOTE, ANY TAX EXPERTS.THAT YOU HAVE CONSULTED ARE.ENGAGED IN PURE SPECULATION..THERE IS NO NEWS HERE..AND GUYS, IF YOU WANT TO GET A.SENSE OF WHERE THE RACE IS JUST.ONE WEEK OUT FROM ELECTION DAY,.YOU CAN JUST KIND OF LOOK AT THE.MAP, GET A SENSE OF WHERE.HILLARY CLINTON IS, WHERE DONALD.TRUMP IS, WHERE THEIR TOP.SURROGATES ARE..THAT\\'S HOW YOU KNOW HOW THINGS.ARE ACTUALLY GOING..TAKE A LOOK..DONALD TRUMP, HE WILL BE IN.WISCONSIN AND PENNSYLVANIA.TODAY..VERY BIG SPEECH WITH RUNNING.MATE MIKE PENCE IN PENNSYLVANIA.ABOUT OBAMACARE..HILLARY CLINTON, SHE WILL BE IN.FLORIDA, HOPPING ON THE PLANE.WITH HER IN A COUPLE HOURS..PRESIDENT OBAMA, HE\\'S GOING TO.OHIO..VICE PRESIDENT JOE BIDEN, HE\\'S.IN NORTH CAROLINA..SO WHAT DOES THAT ALL MEAN?.WHERE HILLARY CLINTON AND HER.TOP SURROGATES ARE GOING, THOSE.ARE TRUE BACKGRTTLEGROUNDS..WHERE DONALD TRUMP IS HEADING,.THOSE ARE PLACES WHERE HILLARY.CLINTON IS FAVORED..HE NEEDS UPSETS IF HE WANTS TO.WIN THIS RACE..THAT\\'S WHAT THE MAP IS SHOWING.RIGHT NOW..THE TRUMP CAMPAIGN SAYS THEY\\'RE.ON OFFENSE..THEY THINK THEY\\'VE GOT PLACES TO.MOVE RIGHT NOW..CLINTON CAMPAIGN SAYS THAT\\'S.JUST PURE DESPERATION..GUYS?.>> AND BOTH TAKES ARE BECAUSE OF.WHAT WE JUST HEARD FROM THE FBI.DIRECTOR..PHIL MATTINGLY, THANK YOU VERY.MUCH..NO QUESTION HIS DECISION CHANGED.THE STATE OF PLAY..LET\\'S DISCUSS..POLITICAL REPORTER FOR \"THE.WASHINGTON POST,\" PHILLIP BUMP..CNN POLITICAL ANALYST AND.WASHINGTON BUREAU CHIEF FOR THE.DAILY BEAST, JACKIE KUCINICH..AND CNN POLITICAL ANALYST DAVID.GREGORY..MR. BUMP, YOU HAVE JIM COMEY,.WHO GOES FROM MAKING A CALL THAT.IT ISN\\'T A CLOSE CALL TO MAKING.A CALL THAT KEEPS THIS ELECTION.CLOSE..DOES HE DESERVE THE CRITICISM OF.THE POLITICAL OVERTONES AND THE.TIMING?.>> IT SEEMS PRETTY CLEAR THAT,.YOU KNOW, PEOPLE WHO KNOW THIS.FAR BETTER THAN I DO ARE.CRITICIZING THE TIMING OF THIS,.SAYING IT IS A STEP OUTSIDE OF.WHAT NORMAL PROCEDURE IS..I THINK IT SEEMS PRETTY CLEAR HE.DESERVES CRITICISM FOR THAT..THE RACE, HOWEVER, SEEMED TO.HAVE BEEN TIGHTENING EVEN BEFORE.COMEY..WE HAVEN\\'T SEEN POLL RESULTS YET.WHICH SUGGEST THE COMEY.REVELATION ON FRIDAY REALLY.AFFECTED THINGS LAST WEEK..I\\'M NOT SURE I REALLY BUY IT..>> HE LITERALLY THANKED HUMA.ABEDIN AND ANTHONY WEINER..ON THE LIST OF I\\'VE NEVER.HEARDS..I\\'VE NEVER HEARD A CANDIDATE FOR.PRESIDENT THANK PEOPLE WHO.BROUGHT CONTROVERSY, EVEN.WITHOUT BASIS, INTO THE CAMPAIGN.INSTEAD OF MAKING A CASE FOR.THEMSELVES, EVER..>> IN THEORY, DOWN BALLOT SHOULD.BE THANKING THEM..I THINK THAT\\'S WHERE WE MIGHT.SEE SOME OF THE MOVEMENT..DOWN BALLOT CANDIDATES CAN.NOW -- LIKE SOMEONE RUNNING FOR.SENATE OR HOUSE, CAN NOW TALK.ABOUT HILLARY CLINTON INSTEAD OF.HAVING TO DEFEND DONALD TRUMP.AND WHATEVER BOMBASTIC THING HE.SAID THAT DAY..AT LEAST FOR THIS PARTICULAR.NEWS CYCLE..WHILE PEOPLE ARE GOING TO THE.POLLS EARLY, THEY\\'RE CASTING.THEIR VOTES, AND THESE.REPUBLICAN CANDIDATES AREN\\'T.TALKING ABOUT DONALD TRUMP..THAT\\'S GOOD..>> I MEAN, LOOK, DAVID..AT FIRST IT SOUNDED LIKE A.BOMBSHELL..OH, MY GOSH, MAYBE THOUSANDS OF.E-MAILS PREVIOUSLY UNDISCLOSED,.FOUND ON THIS LAPTOP..UNTIL YOU DIG IN AND FIGURE OUT.THAT AT LEAST JAMES COMEY.DOESN\\'T KNOW ANYTHING ABOUT.THEM..MAYBE THEY\\'RE DUPLICATES..MAYBE THEY\\'RE NOT RELEVANT OR.PERTINENT, AS HE SAID..SO NOW THAT THE DUST HAS SETTLED.AND PEOPLE GOT MORE WORD THAT WE.REALLY HAVE NO IDEA WHAT THESE.E-MAILS ARE AND THEY MAY BE.NOTHING, WHAT DO YOU THINK THE.EFFECT IS ON THE ELECTION?.>> WELL, WE SIMPLY DON\\'T KNOW,.OTHER THAN THE OBVIOUS, WHICH IS.THERE\\'S A LOT MORE FOCUS ON THIS.THAN DONALD TRUMP..IF THERE\\'S A GUIDING LIGHT IN.THIS CAMPAIGN, IT IS THAT A.MAJORITY OF AMERICANS, UPWARDS.OF 60%, BELIEVE THAT DONALD.TRUMP IS NEITHER QUALIFIED NOR.HAS THE TEMPERAMENT TO BE.PRESIDENT..THAT\\'S A VERY IMPORTANT ATTACK.AREA FOR HILLARY CLINTON..AND SHE\\'S TRYING TO REVIVE IT ON.THE CAMPAIGN TRAIL YESTERDAY AS.SHE\\'S TALKING ABOUT DONALD.TRUMP..SO THIS TAKES SOME OF THAT.ATTENTION AWAY..WE WERE A WEEK AGO TALKING ABOUT.HOW THIS WAS A CAMPAIGN THAT WAS.ONLY ABOUT DONALD TRUMP..NOW IT\\'S A REMINDER OF WHAT.PEOPLE DON\\'T LIKE ABOUT HILLARY.CLINTON..THAT\\'S A PROBLEM..I DO THINK THERE\\'S A HIGH DEGREE.OF CONFIDENCE IF YOU HEAR.SECRETARY CLINTON ON THE TRAIL.THAT THESE ARE DUPLICATE E-MAILS.OR THERE\\'S CERTAINLY NOT.ANYTHING UNTOWARD ABOUT THEM.THAT HAVEN\\'T ALREADY BEEN.INVESTIGATED, WHICH IS WHAT\\'S SO.DISRUPTIVE ABOUT PUTTING ALL OF.THIS INTO THE RECORD NOW..>> WELL, NORMALLY CAREFUL WITH.HER WORDS WHERE IT CONCERNS HER.OWN EXPOSURE, FOR HER TO SAY.THERE\\'S NO CASE, IT IS UNUSUAL..SO LET\\'S PLAY TO THE OTHER SIDE.OF THE BALL..PEOPLE WHO ARE WORRIED ABOUT.TRUMP\\'S QUALIFICATIONS,.TEMPERAMENT, WHATEVER WORD YOU.WANT TO PUT ON IT, THEY HAVE NEW.FOOD FOR THOUGHT ALSO..COMEY DIDN\\'T WANT TO TALK ABOUT.THIS SUGGESTED INVESTIGATION.INTO TRUMP AND RUSSIA THEY HAVE.BECAUSE IT\\'S TOO CLOSE TO.ELECTION, BUT HE WILL TALK ABOUT.E-MAILS HE HASN\\'T READ YET..THE REPORTERS NOW PUTTING OUT.DIFFERENT VERSIONS OF WHAT THEY.SAY IS THE TRUTH ABOUT TRUMP..THAT SOME SPY CAME OUT TO.\"MOTHER JONES\" MAGAZINE AND SAID.HE HAD BEEN ASKED TO DO RESEARCH.AND FOUND THE INVENTION OF SOME.KIND OF SERVER THAT TRUMP HAS..TRUMP\\'S CAMPAIGN SAYS THIS IS,.YOU KNOW, JUNK, THAT IT DOESN\\'T.EXIST..BUT ALL THESE HEADLINES ON YOUR.SCREEN RIGHT NOW ARE COMING OUT.ABOUT TIES BETWEEN TRUMP AND.RUSSIA..DOES ANY OF IT STICK?.WE HAVE TO SAY, A LOT OF THAT.STUFF IS UNCORROBORATED AND.PROBABLY NOT A COINCIDENCE,.ALTHOUGH THE WRITERS WILL SAY,.NO, WE WERE WORKING ON THIS..>> I THINK THE REPORTING, WHICH.ACTUALLY CITES WHAT THE FBI IS.SAYING ABOUT ANY POSSIBLE LINKS.BETWEEN TRUMP AND RUSSIA, YOU.SAW THE CNBC HEADLINE..I THINK THAT\\'S SOMETHING WORTH.DIGGING INTO..THERE WAS A \"NEW YORK TIMES\".REPORT OUT LAST NIGHT THAT.SUGGESTED THE FBI DIDN\\'T FIND.ANY REAL LINKS..I THINK THERE\\'S A LOT OF.SPECULATIVE STUFF OUT THERE..I THINK AT THE END OF THE DAY,.THE QUESTION FOR DONALD TRUMP,.AS DAVID GREGORY JUST SAID, HAS.ALWAYS BEEN, DO PEOPLE SEE HIM.AS PRESIDENTIAL..MORE THAN HALF IN HER SINGLE.ABC/\"WASHINGTON POST\" POLL,.PEOPLE HAVE SAID DONALD TRUMP IS.NOT QUALIFIED TO BE PRESIDENT..I\\'M NOT SURE IT ACTUALLY DOES.ANYTHING TO HELP OR HURT DONALD.TRUMP INDIVIDUALLY..>> IF YOU LOOK AT THE PIECE IN.\"SLATE\" ABOUT A POTENTIAL.CONNECTION, THERE\\'S A STRONG.STORY BETWEEN TRUMP SERVERS AND.RUSSIA..BUT WE DON\\'T KNOW WHERE ALL OF.THIS GOES AS A MATTER OF.INVESTIGATION..BUT THIS KIND OF MAKES THE POINT.THAT THE CLINTON CAMPAIGN IS.TRYING TO MAKE, WHICH IS WAIT A.MINUTE, THIS IS A LOT OF RANGE.OF SPECULATION, INCLUDING FROM.DONALD TRUMP, SUGGESTING THAT.THESE E-MAILS THEY\\'RE LOOKING AT.OF HILLARY CLINTON, YOU KNOW,.ARE PART OF THE CACHE OF E-MAILS.THAT WERE DELETED..THERE\\'S NO EVIDENCE THAT\\'S THE.CASE AT ALL..THAT IS NOT, IN FACT, THE CASE..HE\\'S JUST PUTTING THAT OUT THERE.WILLY NILLY..AND YOU HAVE THE FBI SAYING.THEY\\'RE INVESTIGATING THIS, NOT.TALKING ABOUT THE RUSSIA PIECE..THE POLITICAL DIMENSION OF ALL.THIS, BECAUSE WE\\'RE IN A ZONE OF.UNKNOWN, IS FIRING UP THE.DEMOCRATIC BASE..IT MAY HAVE BEEN A LITTLE SOFT.ON HILLARY CLINTON..NOW MAKING THE ARGUMENT, LOOK,.YOU GOT TO GET OUT THERE AND DO.THIS..THIS IS A CASE OF CLINTON\\'S.ENEMIES OVERREACHING..THAT\\'S THE ARGUMENT HERE..I THINK THAT\\'S WHAT THEY WANT TO.MAKE DOWN THE STRETCH..>> I WAS GOING TO MAKE THE POINT.THAT SENATOR HARRY REID SENT.THIS FIERY LETTER TO JAMES COMEY.SAYING, COME ON, COME OUT WITH.IT, REVEAL WHAT WE KNOW BECAUSE.WE\\'VE BEEN BRIEFED..YOU ARE INVESTIGATING ABOUT THE.TIES BETWEEN TRUMP AND RUSSIA..>> AND MANAFORT ALSO..HE WAS THE CAMPAIGN MANAGER..THERE\\'S SPECULATION ON THE OTHER.SIDE THAT THE REASON THEY GOT.RID OF MANAFORT WASN\\'T HOW HE.WAS MANAGING THE CAMPAIGN BUT.WHAT THEY EVENTUALLY REALIZED,.HIS LIABILITY WAS IN TERMS OF.HIS CONNECTIONS..>> BUT INSTEAD, LET\\'S GET TO.SOMETHING THAT DONALD TRUMP HAS.NOT DENIED..THAT IS THAT HE HAS NOT PAID.TAXES FOR --.>> CELEBRATED IT..>> HE HASN\\'T PAID FOR A COUPLE.OF DECADES..NOW THERE\\'S THIS NEW \"NEW YORK.TIMES\" REPORT THAT SAYS HE USED.A VERY SKETCHY, THEY SAY,.DUBIOUS LOOPHOLE THAT, IN FACT,.HIS TAX ADVISERS ADVISED HIM NOT.TO USE BECAUSE IT WOULD COME TO.THE ATTENTION OF THE IRS..BUT BASICALLY, THAT HE AVOIDED.PAYING FEDERAL PERSONAL INCOME.TAXES FOR YEARS..JACKIE, WHAT IS INTERESTING.ABOUT THIS IS REMEMBER WHEN.REPUBLICANS SAW THAT AS A HUGE,.YOU KNOW, STAIN, AS HUGE.LIABILITY..REMEMBER HOW MITT ROMNEY SAID.47% OF THE COUNTRY ISN\\'T PAYING.TAXES AND THAT WAS SEEN AS SUCH.A CRITICISM..NOW IT\\'S OKAY THAT DONALD TRUMP.DOESN\\'T PAY PERSONAL INCOME.TAXES?.>> WHAT\\'S NOT OKAY IS WE HAVEN\\'T.SEEN DONALD TRUMP\\'S TAXES AND HE.HASN\\'T RELEASED THEM, BREAKING.WITH YEARS AND YEARS OF.PRECEDENT..BUT NO, THIS IS VERY BASIC..THIS IS FAIRNESS..AND THIS IS DONALD TRUMP DID NOT.PAY TAXES..HE\\'S THIS RICH GUY, AND HE USED.A UP OF THESE LOOPHOLES BECAUSE.HE CAN DO IT TO GET OUT OF.PAYING TAXES..I THINK THAT -- THE INTRIGUE.WITH RUSSIA IS REALLY.INTERESTING, AND IF IT\\'S TRUE,.IT COULD BE VERY, VERY.IMPORTANT, BUT THIS IS VERY EASY.TO UNDERSTAND AND VERY STRAIGHT.FORWARD..I THINK THAT MIGHT HAVE MORE.IMPLICATIONS THAN PERHAPS THE.RUSSIAN SPECULATION AT THIS.POINT IN THE RACE..>> ALL RIGHT..WE HAVE TO GO, BUT JUST TO MAKE.THINGS CLEAR, TRUMP\\'S LAWYERS.NEVER TOLD HIM NOT TO DO WHAT HE.WAS DOING..IN A LEGAL LETTER, WHICH BIG.SHOTS ALWAYS GET FROM TAX.ATTORNEYS, THEY SAID THERE WAS.SO LITTLE LEGAL BASIS FOR IT.THAT HE MAY BE EXPOSING HIMSELF.TO PROBLEMS WITH THE GOVERNMENT..NOT, NOT TO DO IT..>> BUT DIDN\\'T THEY ADVISE HIM.NOT TO DO IT?.>> NO, HE DID IT, BUT HE ASKED.THEM FOR A LEGAL OPINION..THEY SAID DUE TO THE LACK OF.DEFINITIVE JUDICIAL OR.ADMINISTRATIVE AUTHORITY,.SUBSTANTIAL UNCERTAINTIES EXIST.WITH RESPECT TO MANY OF THE TAX.CONSEQUENCES OF THE PLAN..>> I UNDERSTAND THAT LEGAL WORD.SALAD PERFECTLY..PANEL, THANK YOU VERY MUCH..ELECTION DAY IS ONE WEEK AWAY..SO BE SURE TO JOIN US NEXT.TUESDAY FOR ELECTION DAY IN.AMERICA..WE\\'LL HAVE EVERY RACE AND EVERY.RESULT COVERED..STAY WITH CNN UNTIL THE LAST.VOTE IS CAST..>>> ALL RIGHT..SO WE HAVE A REPUBLICAN SENATOR.IN NORTH CAROLINA WHO IS.APOLOGIZING FOR A STUNNING QUIP.ABOUT GUN OWNERS TARGETING.HILLARY CLINTON..WAIT UNTIL YOU HEAR WHAT HE.SAID, AND YOU CAN SAY IF IT\\'S A.QUIP OR NOT..      Who says I shouldn\\'t.      have a soda everyday?.           My doctor..           My dentist..       Definitely my wife..    Wait, I know what I want..  Make sparkling water at home..       And drink 43% more.        water every day..           SodaStream..        Love your water..>>> NORTH CAROLINA SENATOR.RICHARD BURR APOLOGIZING AFTER.CNN OBTAINED AUDIO OF HIM MAKING.A TERRIBLE JOKE ABOUT GUN OWNERS.SHOOTING HILLARY CLINTON..CNN\\'S SENIOR POLITICAL REPORTER.MANU RAJU JOINS US WITH MORE..>> Reporter: GOOD MORNING,.CHRIS..THAT INCUMBENT GOP SENATOR, WHO.ALSO CHAIRS THE SENATE.INTELLIGENCE COMMITTEE S.SURPRISINGLY IN ONE OF THE.TOUGHEST RACES IN THE COUNTRY.WITH POLLS IN NORTH CAROLINA.SHOWING HIM TIED WITH A.LITTLE-KNOWN DEMOCRAT DEBORAH.ROSS, IN A RACE THAT COULD.DETERMINE THE NEXT SENATE.MAJORITY..I\\'VE OBTAINED THIS AUDIO OF A.PRIVATE MEETING BURR HAD WITH.VOLUNTEERS WHEN THE SUBJECT OF.CLINTON AND GUNS CAME UP..>> I WALKED INTO A GUN SHOP I.THINK YESTERDAY IN OXFORD..THERE WAS A COPY OF A RIFLE.MAGAZINE ON THE COUNTER..IT\\'S GOT A PICTURE OF HILLARY.CLINTON ON THE FRONT OF IT..I WAS A LITTLE BIT SHOCKED AT.THAT..DIDN\\'T HAVE A BULLSEYE ON IT..>> Reporter: NOW, THAT RESEMBLES.WHAT DONALD TRUMP SAID IN.AUGUST, THAT SECOND AMENDMENT.PEOPLE SHOULD TAKE MATTERS IN.THEIR OWN HANDS WHEN IT COMES TO.CLINTON..BUT UNLIKE TRUMP, BURR.APOLOGIZED WHEN I ASKED HIS.CAMPAIGN FOR COMMENT, SAYING THE.COMMENT WAS, QUOTE,.INAPPROPRIATE AND I APOLOGIZE..NOW, AT THAT SAME MEETING, BURR.ALSO SAID THAT I\\'M GOING TO DO.EVERYTHING I CAN TO ENSURE.CLINTON CANNOT FILL THAT FINAL.SUPREME COURT SEAT, WANTED TO.KEEP IT VACANT FOR FOUR YEARS..HE PRAISED DONALD TRUMP AT THAT.MEETING, SAYING, QUOTE, DONALD.TRUMP ALIGNS PERFECTLY WITH.WHERE THE GOP IS TODAY..>> MANU, THANKS SO MUCH FOR ALL.OF THAT..SO COULD SENATOR BURR\\'S HAVE ANY.IMPACT ON HIS RACE AND THE.SENATE MAJORITY?.HE IS FIGHTING A TOUGH.RE-ELECTION BID IN THE BATTLE.BACKGROUND STATE OF NORTH.CAROLINA..DAVID, DO YOU THINK THERE ARE.ANY REPUERCUSSIONS?.>> WELL, THERE VERY WELL COULD.BE..SENATOR BURR IS RESPONSIBLE FOR.THE COMMENTS HE MADE..REALLY OVER THE LINE,.INAPPROPRIATE..THIS CASUAL TALK ABOUT VIOLENCE.AGAINST HILLARY CLINTON, WHICH.HE HAS MADE, AND YOU\\'RE RIGHT,.DONALD TRUMP HAS MADE ON.NUMEROUS OCCASIONS..THERE WERE SUPPORTERS OF TRUMP.IN NEW HAMPSHIRE, A STATE.SENATOR THAT TALKS ABOUT HILLARY.CLINTON SHOULD BE SHOT FOR.TREASON..I DON\\'T KNOW WHERE THESE PEOPLE.THINK THIS IS APPROPRIATE PUBLIC.DISCOURSE TO TALK ABOUT.ASSASSINATING HILLARY CLINTON..AND ARE THEY NOT NIMBLE ENOUGH.OF MIND TO COME UP WITH A.DIFFERENT ANALOGY WHEN SPEAKING.ABOUT THE GUN DEBATE?.THERE OUGHT TO BE REPERCUSSIONS,.AND PEOPLE WILL MAKE A JUDGMENT.ABOUT THIS..WHEN YOU SAY AWAY FROM CAMERAS.AND WHEN YOU THINK NOBODY IS.LISTENING IS INSTRUCTIVE ABOUT.YOUR OVERALL APPROACH AS A.SENATOR, YOU KNOW, IN THE UNITED.STATES..AND BY THE WAY, SEPARATE FROM.THAT BUT ALSO DISTURBING IS TO.MAKE A PROMISE TO COMPLETELY.OBSTRUCT OUR DEMOCRATIC PROCESS.OF HAVING THE PRESIDENT FILL A.SUPREME COURT VACANCY, WHICH IS.WHY WE HAVE ELECTIONS IN THIS.COUNTRY, SO THAT PRESIDENTS CAN.CHOOSE TO FILL THOSE VACANCIES.IN THE WAY THEY SEE FIT..SO I DON\\'T THINK HE\\'S SHOWERING.HIMSELF IN GLORY HERE IN A TIGHT.RACE..>> AND THAT\\'S NO THROWAWAY.COMMENT..WE KNOW TED CRUZ IS GOING TO TRY.AND MAKE THAT MANIFEST IN A VERY.REAL WAY..WE THOUGHT WE\\'VE SEEN.OBSTRUCTION SO FAR..WE PROBABLY HAVEN\\'T SEEN.ANYTHING YET IF HILLARY CLINTON.BECOMES PRESIDENT..BUT LET\\'S TALK ABOUT WHY THIS.MATTERS..IT\\'S A THROWAWAY COMMENT..HE\\'S TALKING TO VOLUNTEERS..HE DIDN\\'T KNOW IT WAS GOING TO.GET THIS BROAD AN AUDIENCE..ALL TRUE..BUT THE REASON IT\\'S NOT A QUIP.IS BECAUSE A QUIP IS SOMETHING.THAT\\'S CLEVER AND WITTY AND.FUNNY..THIS IS NONE OF THOSE THINGS..BUT IT IS EFFECTIVE..YOU GET A FEEL FOR WHAT\\'S GOING.TO WORK AND WHAT ISN\\'T..YOU DON\\'T SAY, I\\'M SURPRISED YOU.DIDN\\'T HAVE A TARGET ON HER, IF.HE WAS TALKING ABOUT SOMETHING.HE FELT WOULD OFFEND, THAT COULD.HURT HIM..WAT DOES THAT TELL YOU ABOUT.WHAT THE FEELINGS ARE ABOUT WHAT.WORKS WITH THAT BASE?.>> YEAH, I MEAN, THIS IS A GOP.RALLY..THIS IS A GET OUT THE VOTE.RALLY..HE\\'S TRYING TO GET THEM.INVIGORATED TO TALK TO VOTERS.AND GET THEM TURNED OUT..IT\\'S INCREDIBLY STUPID TO SAY..IT\\'S A DUMB JOKE..>> GOT A GOOD LAUGH IN THE ROOM..>> SURE, RIGHT..THERE IS -- TO AN EXTENT, THIS.IS A MICROCOSM OF WHAT YOU SEE.WITH DONALD TRUMP..FEEDING OFF THE AUDIENCE, SAYING.WHATEVER YOU WANT..DONALD TRUMP DOES THAT ALL THE.TIME..>> BUT WITH THAT AUDIENCE..I\\'VE BEEN TO G.O.T. RALLIES..I NEVER HEARD ANYBODY SAY MAYBE.WE SHOOT THAT OPPONENT..>> EXACTLY..BUT YOU THINK THAT PAIRED WITH.THE SUPREME COURT THING SHOWS.HOW POLITICS HAS CHANGED..THE FACT YOU\\'RE TALKING ABOUT.SUPREME COURT OBSTRUCTIONISM AND.AS THOUGH IT\\'S APPROPRIATE TO.MAKE A JOKE ALONG THAT LINE..>> JACKIE, LET\\'S TALK ABOUT.SEXISM..THERE ARE LOTS OF PEOPLE, WOMEN.PRIM.PRIMARILY, WHO THINK THE.CRITICISMS AGAINST HILLARY.CLINTON JUST SMACK OF SEXISM.THROUGH AND THROUGH, THAT THEY.WOULDN\\'T BE THE SAME CRITICISMS.USED IF SHE WERE A MAN RUNNING..SO LAST NIGHT, SAMANTHA BEE ON.HER COMEDY SHOW BROUGHT THIS UP.WITH HER GUEST, PRESIDENT OBAMA..LISTEN TO THIS..>> IF AND WHEN HILLARY IS.PRESENT, WHAT DO YOU THINK.WILL BE THE FEMALE EQUIVALENT OF.YOU WEREN\\'T BORN IN THIS.COUNTRY?.>> THAT\\'S AN INTERESTING.QUESTION..>> THANK YOU..I HAVE A LOT OF THOSE..>> I THINK THE EQUIVALENT WILL.BE SHE\\'S TIRED, SHE\\'S MOODY,.SHE\\'S BEING EMOTIONAL..>> THERE\\'S JUST SOMETHING ABOUT.HER..>> THERE\\'S SOMETHING ABOUT HER..WHEN MEN ARE AMBITIOUS, IT\\'S.JUST TAKEN FOR GRANTED..WELL, OF COURSE THEY SHOULD BE.AMBITIOUS..WHEN WOMEN ARE AMBITIOUS, WHY?.THAT THEME, I THINK, WILL.CONTINUE THROUGHOUT HER.PRESIDENCY, AND IT\\'S CONTRIBUTED.TO THIS NOTION THAT SOMEHOW SHE.IS HIDING SOMETHING..>> WHAT A NASTY WOMAN..>> THE FIRST SPIN OF THIS.INTERVIEW THAT I READ THIS.MORNING WAS OBAMA SAYS CLINTON\\'S.AMBITION A PROBLEM AS PRESIDENT..>> OBAMA SAYS CLINTON\\'S A NASTY.WOMAN..>> ALTHOUGH, I WILL SAY, THE.NASTY WOMAN, THE HILLARY CLINTON.CAMPAIGN HAS TAKEN THAT AND.OWNED IT..YOU SEE IT ON SHIRTS EVERYWHERE.AROUND THE COUNTRY..>> THEY\\'VE TURNED IT INTO THE.JANET JACKSON VERSION..>> TRUMP HAD A MOMENT OF.EMOTIONAL HONESTY UP THERE..THAT\\'S WHAT CAME OUT OF HIM..WHEN HE HEARS A WOMAN KICKING.HIS BUTT ON TELEVISION, THAT\\'S.WHAT COMES OUT OF HIM..BOY, SHE\\'S NASTY..BECAUSE THAT\\'S NOT WHAT HE.EXPECTS..>> RIGHT..I THINK IT DEPENDS ON WHAT ISSUE.YOU\\'RE TALKING ABOUT..IF YOU\\'RE TALKING ABOUT SHE\\'S.EMOTIONAL AND SOME OF THE THINGS.THAT WERE JUST BROUGHT UP IN.THAT INTERVIEW, ABSOLUTELY..THAT IS LOOKING AT IT THROUGH A.LENS OF SEXISM..BUT I\\'VE ALSO -- BUT ON THE SAME.TOKEN, I\\'VE HEARD HER CRITICISM.OF THE E-MAIL SERVER AND SOME OF.THE THINGS THAT HAPPENED AT THE.STATE DEPARTMENT AS BEING.SEXIST, WHICH JUST ISN\\'T THE.CASE..>> PANEL, THANK YOU..GREAT TO TALK TO YOU ALL..UP NEXT, THE FUTURE OF THE.SUPREME COURT..IF HILLARY CLINTON WINS THE.PRESIDENCY, WILL REPUBLICANS TRY.TO KEEP THE COURT AT JUST EIGHT.JUSTICES?.WE DISCUS HOW THAT WOULD BE.POSSIBLE NEXT..TV: Oh, it\\'s gonna get crazy!.This is Black Friday.That is insane..I would never do that..At Chevy, you can avoid the.chaos and.get great deals on the most.awarded lineup..I like that..Bam!.It\\'s awesome!.You don\\'t have to camp out at.the Chevy dealer.two days in advance..I love it. (laughs).Wow..And you don\\'t have to wait until.          Black Friday..      Find your tag and get.          20% cash back,.     or, get 0% financing for.            months on.   select remaining 2016 Chevy.        vehicles in stock..   Find new roads at your local.          Chevy dealer..               Abdominal Pain?.                  Bloating?.              You may have IBS..              Ask your doctor if.               non-prescription.                   IBgard is.                 right for you..                 IBgard calms.                the angry gut..               Available at CVS,.         Walgreens and Rite Aid..>>> COMEY SAYS IT\\'S NOT EVEN A.CLOSE CALL, THERE\\'S NO CASE..THE REPUBLICANS, BOO..NOW COMEY SAYS I\\'M GOING TO MAKE.A CALL THAT\\'S GOING TO KEEP IT A.CLOSE CASE..THEY LOVE HIM..OF COURSE, DEMOCRATS HAVE THE.EXACT OPPOSITE SPOT OF REACTION..WHAT DOES THAT DO FOR COMEY?.PUTS HIM IN A TOUGH PLACE WITH.JUST SEVEN DAYS BEFORE THIS.ELE.ELECTION..BUT PEOPLE DON\\'T REALLY CARE.ABOUT HIM..LET\\'S DISCUSS THE IMPACT ON THE.ELECTION WITH JEFFREY TOOBIN AND.CNN CONTRIBUTOR AND SENIOR.EDITOR AT \"THE ATLANTIC,\" MR..DAVID FRUM..JEFFREY, ON THE LEGAL SIDE, THE.CRITICISM IS THAT THE FBI.DOESN\\'T USUALLY TALK, AND COMEY.BREACHED PROTOCOL TWICE AND BOTH.TIMES TO ILL EFFECT..THE SECOND TIME NOW WITHOUT ANY.BASIS OF FACT TO SUPPORT THE.DISCLOSURE..HOW DO YOU SEE IT, FAIR.CRITICISM?.>> WELL, I THINK THE KEY ISSUE.IS THE TIMING..YOU KNOW, EVEN I, A LOWLY.ASSISTANT U.S. ATTORNEY IN THE.1990s, KNEW THAT ONE OF THE.THINGS THE JUSTICE DEPARTMENT,.INCLUDING THE FBI, NEVER DID WAS.MAKE AN ANNOUNCEMENT THAT.AFFECTED AN ELECTION IN THE LAST.TWO MONTHS..THIS IS JUST A RULE THAT\\'S BEEN.IN EXISTENCE AT THE JUSTICE.DEPARTMENT FOR DECADES..WE CAN ARGUE ABOUT WHETHER COMEY.SHOULD HAVE MADE EITHER OF THESE.STATEMENTS, THE ELABORATE.EXPLANATION OF THE EXONERATION.AND THE ANNOUNCEMENT OF THE NEW.INVESTIGATION..WHAT\\'S REALLY TROUBLING IS THE.TIMING..DOING IT 11 DAYS BEFORE THE.ELECTION WHEN YOU DIDN\\'T HAVE TO.DO IT AT ALL, I THINK THAT\\'S WHY.YOU\\'VE SEEN SO MUCH CRITICISM OF.COMEY BY REPUBLICAN AS WELL AS.DEMOCRATIC VETERANS..>> SO DAVID, WHAT DO YOU THINK.THIS DOES TO THE ELECTION?.>> WELL, THE GREAT CHALLENGE.DEMOCRATS HAVE IS CAN THEY MATCH.THE HEROIC TURNOUT PERFORMANCE.OF 2012..THAT WAS AN ELECTION WHERE.VOTING PERFORMANCE WENT DOWN.THROUGH MOST GROUPS, BUT AMONG.CERTAIN KEY DEMOCRATIC.CONSTITUENCIES, ESPECIALLY.AFRICAN-AMERICANS, THERE WAS A.HEROIC TURNOUT PERFORMANCE..HIGHER IN 2012 FROM 2008..HIGHER AMONG BLACKS THAN AMONG.WHITES..WHEN YOU LOOK MORE CLOSELY, YOU.SEE A LOT OF THAT WAS BECAUSE.THE TURNOUT HAD BEEN INCREDIBLE.IN 2008..OLDER PEOPLE PROBABLY NOT IN THE.BEST OF HEALTH WHO HAD MADE THAT.SPECIAL EFFORT TO GO TO THE.POLLS..WILL THAT HAPPEN AGAIN FOR THE.LESS INSPIRING HILLARY CLINTON.CAND.CANDIDACY?.IF THERE\\'S NEWS THAT MAKES.DEMOCRATS LESS ENTHUSIASTIC,.REPUBLICAN CONSTITUENCIES TEND.TO VOTE..THEY\\'RE THE PEOPLE WHO PAY THEIR.CABLE BILLS ON THE DAY IT.ARRIVES..DEMOCRATS, MAYBE YES, MAYBE NO..>> HOW DOES THIS PLAY TO THEM IN.TERMS OF IS THIS SOMETHING THAT.MAKES THEM SAY, OH, I GUESS SHE.HAS REAL TROUBLE, OR DOES IT.MAKE THEM PLAY THE, WOW, LOOK,.THEY\\'RE REALLY OUT TO GET HER..THIS GUY HASN\\'T EVEN LOOKED AT.THE E-MAILS YET AND HE\\'S COMING.OUT THIS CLOSE TO AN ELECTION.WHEN I\\'VE HEARD PEOPLE LIKE.JEFFREY SAY YOU\\'RE NOT SUPPOSED.TO DO THAT..>> I THINK MY OWN ATTITUDE.TOWARDS SPORTS..I GENERALLY KNOW 48 HOURS BEFORE.THE SUPER BOWL WHO\\'S IN IT..I MAY KNOW THE NAME OF ONE OF.THE QUARTERBACKS..BUT THAT\\'S IT..AND I CAN BE EASILY INFLUENCED.BY STRAY BITS OF INFORMATION..IN THE SAME WAY, LATE DECIDING.VOTERS DO NOT FOLLOW POLITICS.CLOSELY..IT DOESN\\'T MATTER WHETHER IT\\'S.GOT CONTENT OR NOT, IT AFFECTS.THEM..IF IT MAKES THEM LESS LIKELY TO.TURN OUT FOR HILLARY CLINTON,.THAT\\'S BIG NEWS..MEANWHILE --.>> DAVID, I\\'M A NEW YORK JETS.FAN..JUST SO YOU KNOW, WE\\'RE NEVER IN.THE SUPER BOWL..THAT MAY BE ABLE TO HELP YOU..>> THANK YOU..THANK YOU FOR THAT..>> ALL RIGHT..JEFFREY, LET\\'S TALK ABOUT THE.SUPREME COURT..AS YOU KNOW, OF COURSE, THE.NOMINATION OF MERRICK GARLAND.HAS BEEN HELD UP BY REPUBLICANS,.BASICALLY SAYING IT\\'S TOO CLOSE.TO AN ELECTION..WHAT HAPPENS AFTER THE ELECTION?.LET\\'S SAY HILLARY CLINTON WINS..IS THERE A WAY FOR REPUBLICANS.TO OBSTRUCT ANY NOMINEE THAT SHE.PUTS FORWARD AND TO TRY TO KEEP.THE COURT AT EIGHT JUSTICES?.>> ABSOLUTELY..THE IMPORTANT THING TO REMEMBER.IS THAT THE CONFIRMATION PROCESS.IS A POLITICAL PROCESS, NOT A.LEGAL PROCESS..AND IT IS ENTIRELY UP TO THE.UNITED STATES SENATE, WHICH IS.OF COURSE A POLITICAL BODY..THERE\\'S A HISTORY OF VOTING.AGAINST SUPREME COURT NOMINEES..REMEMBER, IN THE NIXON.ADMINISTRATION IT TOOK THREE.NOMINEES TO FILL THE SEAT THAT.ULTIMATELY WENT TO HARRY.BLACKMAN..RONALD REAGAN HAD TO NOMINATE.THREE PEOPLE BEFORE ANTHONY.KENNEDY WAS CONFIRMED..WHAT\\'S UNPRECEDENTED IF IT.HAPPENS IS SIMPLY NOT VOTING..THAT HAS NEVER BEEN DONE AS A.MODE OF OBSTRUCTION..YOU CAN VOTE DOWN NOMINEES..THAT\\'S BEEN DONE MANY TIMES..I THINK THAT WOULD BE.POLITICALLY DIFFICULT, SIMPLY.NOT TO VOTE ON ANY OF HILLARY.CLINTON\\'S NOMINEES, BUT VOTING.NO IS CERTAINLY AN APPROPRIATE.FUNCTION OF WHAT SENATORS CAN.DO..>> DAVID, CAN WE SAY IT, EIGHT.JUSTICES?.>> WE CAN\\'T BECAUSE YOU HAVE GOT.TIED..>> WELL, YOU CAN..THAT\\'S THE TED CRUZ ARGUMENT..I HEARD JEFFREY TOOBIN, WHO AS.WE BOTH KNOW IS A SUPREME COURT.SCHOLAR, SCREAMING IN DISGUST.WHEN TED CRUZ MADE THAT.STATEMENT..FUNCTIONALLY, HE JUMPED ON ONE.OF THE JUSTICES SAYING THINGS.DAY TO DAY ARE WORKING THE SAME.WAY..HE SAID, SEE, IT\\'S OKAY..BUT IT ISN\\'T OKAY..>> IT\\'S AN EVEN NUMBER..HERE\\'S THE WAY YOU OUGHT TO HEAR.THAT REMARK..THESE ARE TACTICS..THESE ARE BIDS BEING LAID DOWN.IN ADVANCE OF THE INFORMATION.ABOUT HOW STRONG WILL THE.RESPECTIVE POSITIONS BE OF THE.PARTIES..IF THIS TURNS OUT TO BE A CLOSE.ELECTION AND IF THE REPUBLICANS.HOLD MOST OF THEIR SENATE SEATS,.THEY HAVE A POSITION TO SAY,.HEY, WE\\'VE GOT A MANDATE TOO..PRESIDENT CLINTON, IF THAT\\'S WHO.IT IS, MUST NEGOTIATE WITH US..IF ON THE OTHER HAND IT\\'S A.HAMMERING AND REPUBLICANS DROP.SEATS, TED CRUZ MAY SAY THAT FOR.HIS OWN INTERNAL REPUBLICAN.PARTY PURPOSES BECAUSE REMEMBER,.HE COMPROMISED HIS BRAND AS THE.PUREST OF THE PURE..HE NOW HAS TO REASSERT HIS BRAND.AS THE PUREST OF THE PURE..AND HE ALSO NEVER THINKS VERY.MUCH ABOUT WHAT THE OTHER.SENATORS THINK OF HIM..>> YOU\\'RE SAYING IF IT\\'S NOT A.CLOSE ELECTION THAT BASICALLY.THE SUPREME COURT NOMINEES MUST.MOVE FORWARD..>> WELL, IT\\'S GOING TO BE -- IF.IT\\'S NOT A CLOSE ELECTION,.REPUBLICANS WILL BE DEMORALIZED..THEY WILL BE TURNING THE WRATH.UPON EACH OTHER..AND AT THAT POINT, THE NEW.PRESIDENT WILL HAVE A LOT OF.POWER..>> DAVID, JEFFREY, THANKS..GREAT TO HAVE THIS CONVERSATION.WITH YOU..>>> SO THE BATTLEGROUND STATE OF.NORTH CAROLINA IS CONSIDERED A.MUST WIN FOR DONALD TRUMP..BUT AT THE MOMENT, THAT STATE.LOOKS LIKE AN UPHILL BATTLE..TAKE A LOOK AT THE LATEST NBC.NEWS/\"WALL STREET JOURNAL\" POLL..CLINTON LEADS TRUMP BY SIX.POINTS IN THE STATE..CNN\\'S JESSICA SCHNEIDER IS IN.RALEIGH, WHERE SHE SPOKE WITH.VOTERS..GOOD MORNING, JESSICA..>> Reporter: GOOD MORNING,.ALISYN..YOU KNOW, ONE VOTING BLOC THAT.IS PARTICULARLY STRESSED OUT.HERE, EVANGELICAL CHRISTIANS..I SPENT SUNDAY HERE AT THIS.CHURCH..THE MEMBERS TELL ME THEY HAVE.NEVER BEEN THIS CONFLICTED ABOUT.A PRESIDENTIAL RACE..THEY SAY THE ISSUES TO THEM ARE.VERY CLEAR, BUT THE CANDIDATE.WHO EMBODIES THEIR IDEALS, A LOT.LESS SO..INSIDE NORTH CAROLINA.EVANGELICAL CHURCHES, THE MOOD.JOYOUS..>> IN A SEASON IN OUR COUNTRY --.>> Reporter: LEADERS ACKN.ACKNOWLEDGING THOUGH, THE.FAITHFUL ARE STRUGGLING..>> I\\'M SEEING STRESS LIKE I\\'VE.NEVER SEEN BEFORE..>> Reporter: MOST OF HIS MEMBERS.ARE RALLYING FOR TRUMP..>> OH, IT WASN\\'T EASY AT ALL..IT WAS A VERY DIFFICULT DECISION.BECAUSE IF I JUST LOOK AT DONALD.TRUMP AS A MAN, THERE\\'S NO WAY.THAT I WOULD EVEN CONSIDER.VOTING FOR HIM..BUT I HAVE TO LOOK AT THE MUCH.BIGGER PICTURE..>> Reporter: FOR MARQUIS, IT.COMES DOWN TO HIS OWN.ANTI-ABORTION STANCE AND THE.FUTURE OF THE SUPREME COURT..BUT WITH TRUMP\\'S THREE MARRIAGES.AND THE RELEASE OF THAT \"ACCESS.HOLLYWOOD\" TAPE, SOME ARE NOW.ASKING, IS THE REPUBLICAN TICKET.THE HIGHEST PICK?.WHITE EVANGELICALS PROPELLED.MITT ROMNEY TO A VICTORY IN THE.STATE IN 2012..THEY MADE UP ABOUT A THIRD OF.ALL VOTERS..>> HIS LIFESTYLE HASN\\'T BEEN ONE.THAT\\'S REPRESENTATIVE OF VALUES.I HOLD..I DON\\'T BELIEVE HE\\'S HONEST WHEN.HE SAYS HE\\'S PRO-LIFE..>> Reporter: JESUS MORALES IS.NEVER TRUMP..HE AND HIS WIFE PLAN TO VOTE FOR.THE REPUBLICAN RUNNING AS AN.INDEPENDENT..HE\\'S ON THE BALLOT IN 11 STATES.BUT NOT NORTH CAROLINA..THEY\\'LL HAVE TO WRITE HIM IN AS.THEIR VOTE..>> I CAN\\'T VOTE FOR SOMEONE WHO.HAS BEEN SO IGNORANT IN HIS.BEHAVIOR TOWARDS WOMEN AND.TOWARDS HANDICAPPED PEOPLE.ESPECIALLY..>> AND YOU ARE HANDICAPPED..>> YES, I\\'M LEGALLY BLIND..IT\\'S INSULTING TO ME HE CAN MAKE.FUN OF THE HANDICAPPED COMMUNITY.AND NO ONE HAS CALLED HIM OUT ON.IT..>> I PERSONALLY PLAN TO VOTE.RELUCTANTLY FOR TRUMP..NOT THAT I IN ANY WAY WOULD WANT.TOP ENDORSE HIM AS A PERSON..>> Reporter: SO IT\\'S BEEN A HARD.DECISION FOR YOU..>> OH, ABSOLUTELY..>> Reporter: RACHEL MILLER IS 22.YEARS OLD, A MILLENNIAL AND A.PRIME TARGET FOR THE NOT WHO WE.ARE PAC, A SUPER PAC DEVOTED TO.DEFEATING TRUMP, RELEASING THIS.MUSIC VIDEO AD, FEATURING.POPULAR CHRISTIAN MUSICIAN.WILLIAM MATTHEWS..>> DONALD TRUMP IS DANGEROUS..>> Reporter: RADIO HOST STEVE.NOBLE VOTED EARLY FOR TRUMP..IT\\'S A PICK HE STRUGGLED WITH..>> I GOT TO DO WHAT I CAN TO.STOP HILLARY..SO I\\'M NOT ENDORSING DONALD.TRUMP..I\\'M NOT A BIG DONALD TRUMP FAN..I\\'M A PRAGMATIST WHO\\'S ALSO A.CHRISTIAN..>> Reporter: STEVE NOBLE CAST.HIS BALLOT FOR DONALD TRUMP ON.FRIDAY..HE TELLS ME HE DIDN\\'T FEEL GOOD.ABOUT IT, BUT NONETHEESS, HE IS.ADVISING HIS LISTENERS TO VOTE.FOR DONALD TRUMP, WHO HE SEES AS.THE LESSER OF TWO EVILS..NOW, THE LATEST CNN POLL.CONDUCTED OCTOBER 20th THROUGH.23rd SHOWS THAT WHITE.EVANGELICALS ARE BREAKING FOR.DONALD TRUMP..72% FOR DONALD TRUMP, 21% FOR.HILLARY CLINTON..CHRIS?.>> ALL RIGHT, JESSICA..THANK YOU VERY MUCH..SO WE\\'RE TALKING ABOUT NOVEMBER.HERE, RIGHT..IT\\'S OFF TO A WARM START..NOT JUST IN THE ELECTION, BUT.LITERALLY BY TEMPERATURE..BIG PARTS OF THE U.S. IN THE.GRIP OF A RECORD-BREAKING HEAT.WAVE..METEOROLOGIST CHAD MYERS HAS THE.FORECAST..IS THE CAUSE THE INTENSE.TOXICITY OF THE ELECTION THAT IS.LITERALLY HEATING UP THE GLOBE?.>> YOU HAD IT GOING, HOT AIR..FOR THE FIRST TIME IN A LONG.TIME, THE SKELETONS AND THE.GHOSTS DIDN\\'T HAVE TO WEAR.PARKAS..THAT CERTAINLY RUINS THE EFFECT.OF HALLOWEEN..A NICE HALLOWEEN ACROSS THE EAST.COAST..ACROSS THE SOUTHEAST, 32 RECORD.HIGHS YESTERDAY..WE EXPECT JUST THE SAME NUMBER.FOR TODAY..TEMPERATURES IN THE 80s WHEN WE.SHOULD BE IN THE 60s..NOW, WATCH WHAT YOU ASK FOR.BECAUSE BY THE END OF THE.WEEKEND, WE\\'RE BACK WHERE WE.SHOULD BE..EVEN NEW YORK CITY DOWN TO A.HIGH OF 50 ON FRIDAY..BUT THAT WILL FEEL PRETTY GOOD.IF YOU\\'RE GOING OUT, MAYBE.PICKING SOME APPLES..I GUESS IT\\'S TOO LATE TO PICK.PUMPKINS..BUT YOU CAN CERTAINLY GET SOME.H.HOT CIDER..>> OKAY..THANK YOU VERY MUCH FOR THAT,.CHAD..>>> MEANWHILE, THE TWO BIGGEST.OCTOBER SURPRISES IN THIS.ELECTION BOTH CONNECTED TO SEX.ACCUSATIONS..WE DISCUSS THAT TOPIC WITH OUR.POLITICAL PANEL NEXT..              ♪  ♪.      Prepare for challenges.    specific to your business.by working with trusted advisors.     who help turn obstacles.       into opportunities..       Experience the power.       of being understood..               RSM..    Audit, tax and consulting.      for the middle market..A NATIONAL CONVERSATION ABOUT.SEXUAL ASSAULT AND WHAT\\'S OKAY..NOW YOU HAVE OVER 11 WOMEN WHO.HAVE COME FORWARD WITH.ALLEGATIONS AGAINST TRUMP..AND THEN YOU HAVE HILLARY.CLINTON\\'S LATEST E-MAIL TROUBLE.THAT NOW IS PERVERSELY CONNECTED.TO ANTHONY WEINER\\'S SEXTING.INVESTIGATION..LET\\'S DISCUSS WITH CNN POLITICAL.ANALYST AND \"USA TODAY\".COLUMNIST KIRSTEN POWERS AND CNN.POLITICAL COMMENTATOR AND.REPUBLICAN CONSULTANT MARGARET.HOOVER..YES, I AM MADE A LITTLE.UNCOMFORTABLE BY THIS.CONVERSATION..I CAN\\'T EVEN STAY IN MY CENTER.BOX..I WANT TO START WITH SOMETHING.ELSE THAT I HEAR A LOT MORE OF.THAN THE IDEA OF THIS BEING.ABOUT SEX, WHICH IS THIS BEING.ABOUT HILLARY CLINTON BEING A.WOMAN..I HEAR THIS FROM A LOT OF WOMEN,.CRITICISM THAT DOES NOT SPARK.SEXISM IN MY MIND..THEY\\'RE GOING AFTER HER FOR HER.PERSONAL QUALITIES..SAMANTHA BEE IN HER INTERVIEW.WITH PRESIDENT OBAMA SEEM ED TO.BE GETTING AT THIS POINT..HELP ME UNDERSTAND IT FROM YOUR.PERSPECTIVE, KIRSTEN..WHAT DO YOU THINK MEN MAY NOT.PICK UP ON ABOUT WHAT\\'S SAID.ABOUT HILLARY CLINTON?.>> WELL, TO ME THE BIGGEST.EVIDENCE OF SEXISM IN THIS RACE.IS THE DOUBLE STANDARD..BY THAT, I MEAN IF YOU HAD.SOMEBODY LIKE DONALD TRUMP WHO.REALLY DOESN\\'T HAVE ANY.EXPERIENCE IN GOVERNMENT, HE.DOESN\\'T KNOW, AS FAR AS I CAN.TELL, ANYTHING ABOUT PUBLIC.POLICY, AND DOESN\\'T REALLY WANT.TO THE KNOW ANYTHING ABOUT.PUBLIC POLICY, HAS ACTUALLY.BRAGGED ABOUT THE FACT HE.DOESN\\'T PREPARE FOR DEBATES, HE.SHOWS UP AT DEBATES AND WALKS.AROUND THE STAGE, INTERRUPTS.HER, BEHAVES IN A WAY I THINK IF.A WOMAN -- I JUST WANT YOU TO.IMAGINE A WOMAN DOING THAT,.CHRIS..HER BEING SUCCESSFUL AND SOMEHOW.GETTING THE NOMINATION AND THEN.ALSO MAYBE POTENTIALLY BEING.PRESIDENT OF THE UNITED STATES..TO ME, IT\\'S UNTHINKABLE..>> IS IT STILL WRONG -- I HEAR.WHAT YOU\\'RE SAYING..I GOT A COUPLE BEATS ON IT..FIRST ONE IS, IS IT EQUALLY.WRONG THAT I WOULDN\\'T EXPECT.THAT OUT OF A WOMAN BECAUSE I.EXPECT MORE OUT OF THEM?.YOU KNOW, THEY DON\\'T ACT IN A.CAVEMAN WAY..IS THAT EQUALLY OFFENSIVE?.>> IT\\'S FRATERNALISTIC..>> SO IT\\'S EQUALLY OFFENSIVE..>> WHY WOULD YOU EXPECT WOMEN TO.BEHAVE BETTER?.>> BECAUSE I THINK THEY\\'RE.SMARTER..I THINK THEY HAVE A BETTER.ABILITY TO THINK THROUGH AN.APPARENT HOSTILITY, WHEREAS MEN.MAY THINK THAT IF YOU FRAME UP.ON ANOTHER GUY AND SHOW THAT.MAYBE YOU COULD TAKE HIM BEHIND.THE HIGH SCHOOL OR WHATEVER THE.HECK VICE PRESIDENT BIDEN SAID,.THAT THAT\\'S OKAY..>> BUT CHRIS, I THINK THAT\\'S.BECAUSE WOMEN HAVE HAD TO LEARN.HOW TO DEAL WITH SEXISM..I DON\\'T THINK IT\\'S FAIR TO.EXPECT THEM TO HAVE TO.CONSTANTLY BE REACHING THIS BAR.WHERE HILLARY CLINTON HAS TO BE.SO GOOD AT STANDING THERE WITH.THIS GUY WHO IS ATTACKING HER.AND DOING THINGS THAT IF A WOMAN.DID WE\\'D CALL HER A PSYCHOPATH.BASICALLY..>> OH, PEOPLE CALL TRUMP THAT.ALSO..>> WELL, BUT HALF THE COUNTRY.IS -- AT LEAST 40 PLUS PERCENT.OF THE COUNTRY..>> NOW YOU MAKE A DIFFERENT.POINT..THERE ARE PEOPLE WHO SAY, WELL,.CONVERSELY, ON OBSERVELY FROM.WHAT WE JUST HEARD, IF HILLARY.CLINTON WERE RUNNING AGAINST ANY.OTHER REPUBLICAN WHO WAS WORTH.THEIR SALT, SHE\\'D BE GETTING.CRUSHED AND THAT HER BEING A.WOMAN IS A HUGE ADVANTAGE FOR.THE DEMOCRATS BECAUSE SHE IS A.FIRST AND THAT THERE\\'S A.SCRUTINY THAT SHE WOULD NOT BE.ABLE TO SURVIVE IF SHE WAS.RUNNING AGAINST ANYBODY BUT.TRUMP..THAT HE\\'S A FAVOR TO HER..>> THERE IS A SCRUTINY ON.HILLARY CLINTON, CERTAINLY..THERE\\'S A SCRUTINY ON HER.BECAUSE SHE\\'S A FIRST WOMAN BUT.ALSO BECAUSE SHE\\'S BEEN IN.PUBLIC LIFE FOR 25 YEARS AND.THERE DO CONTINUE TO BE SCANDALS.AROUND HER IN THE BEHAVIOR AND.CHOICES CAN SHE\\'S MADE..BUT KIRSTEN\\'S RIGHT..AND BY THE WAY, JR. RYOUR RESPOO.HER, THAT THERE SHOULD BE THIS.DIFFERENT STANDARD FOR WOMEN --.>> I\\'M NOT SAYING THERE SHOULD.BE..I\\'M SAYING IN MY HEAD, IN MY.ALPHA MALE HEAD, I DON\\'T SEE.THAT AS A PLAUSIBLE SCENARIO.BECAUSE I WOULDN\\'T EXPECT WOMEN.TO ACT LIKE A BAD MAN..THAT\\'S JUST WHERE MY HEAD IS..>> THERE YOU GO, AMERICA..WELCOME TO THE SEXISM THAT IS.IMPLICIT IN THIS ELECTION..THAT ILLUSTRATES IT..WHAT ELSE CAN I SAY?.YOU MADE THE POINT YOURSELF..BY THE WAY, THE FACT WE\\'RE.TALKING ABOUT SEX SCANDALS --.>> IF YOU SAY YOU EXPECT BETTER.BEHAVIOR FROM WOMEN, YOU\\'RE.HOLDING THEM UP TO A BETTER.STANDARD THAN A GUY LIKE TRUMP,.AND THAT\\'S HOW BAD..>> I TH.>> WE\\'LL HAVE EQUALITY WHEN AN.AVERAGE MAN AND AN AVERAGE WOMAN.ACCELERATE AT THE SAME RATE..THE WOMAN SHOULD HELD TO THE.SAME STANDARD..IN THIS CASE, I DON\\'T THINK THE.MAN IS HELD TO THE SAME.STANDARD..LIKE I SAID, I REALLY HAVE.RACKED MY BRAIN TO IMAGINE A.WOMAN BEHAVING LIE LIKE HIM AND.GETTING THE NOMINATION OF A.MAJOR PARTY..>> HOW ABOUT JUST IMAGINE A.FEMALE SEX SCANDAL..WE STILL HAVE NOT SEEN ONE ON A.NATIONAL LEVEL..THIS IS JUST ABOUT MEN BEHAVING.BADLY..THIS ISN\\'T A FEMALE HAVING AN.AFFAIR OR SEXUALLY ASSAULTING OR.BEING SEXUALLY AGGRESSIVE OR.INAPPROPRIATE TO ANYBODY ELSE..THIS IS ALL ABOUT MALES\\' BAD.BEHAVIOR..>> BUT ISN\\'T THAT ABOUT FACTS?.>> AGAIN, I REFER YOU TO YOUR.EARLIER STATEMENT..THERE\\'S NOT AN EVEN PLAYING.FIELD..THERE\\'S NOT AN EVEN BAR..WOMEN AND MEN ARE BEING HELD TO.DIFFERENT STANDARDS..>> I GET KIRSTEN\\'S POINT..I DON\\'T BELIEVE THAT THE ABSENCE.OF FEMALE SEX SCANDALS MEANS.THIS IS AN UNFAIR PROCESS..>> WHAT I\\'M SAYING IS THIS IS --.WE\\'RE NOT EVEN ON A FAIR PLAYING.FIELD..>> I DON\\'T DISAGREE WITH THAT..I DON\\'T UNDERSTAND HOW -- OF.COURSE YOU SHOULD JUDGE WOMEN.AND MEN THE SAME WAY..THAT\\'S EASY..WHAT I\\'M SAYING IS I THINK THAT.THERE IS A PERCEPTION THAT WOMEN.BEHAVE BETTER THAN MEN IN POINTS.OF CONFRONTATION..IT\\'S NOT THAT IT\\'S A DIFFERENT.STANDARD..IT\\'S A DIFFERENT LEVEL OF.BEHAVIOR..>> IT\\'S JUST BEHAVING BETTER.GENERALLY IN THE PUBLIC SPHERE..>> AND KIRSTEN SAYS THAT\\'S.BECAUSE THEY\\'VE HAD TO LEARN TO..DEEP DOWN, YOU\\'RE JUST AS BAD AS.I AM, BUT YOU\\'VE LEARNED NOT TO.BE THAT WAY?.>> LOVELY..WOMEN ARE JUST BETTER BEHAVED,.WHICH ARE IS WHY WE OUGHT TO.HAVE MORE OF THEM IN ELECTED.OFFICER..>> ALL RIGHT..KIRSTEN, THANK YOU VERY MUCH..HAPPY TO BE THE GUINEA PIG..CAN\\'T WAIT TO READ MY TWITTER.FEED..>> WE\\'RE GOING TO ENLIGHTEN YOU.SLOWLY..>> THANK YOU VERY MUCH..IT WILL TAKE A LONG TIME..WHAT DO YOU THINK ABOUT THIS?.TWEET US @NEWDAY..POST YOUR COMMENT ON FACEBOOK..ALISYN?.>> I DIDN\\'T SEE THE DIRECTION.WHERE THAT WAS GOING TO GO,.CHRIS ON TRIAL..>>> WELL, THE FBI HEAD UNDER.FIRE FOR THE NEW E-MAIL PROBE..LET\\'S BRING IN CNN.COUNTERTERRORISM ANALYST AND.FORMER CIA COUNTERTERRORISM.OFFICIAL AND FBI OFFICIAL PHIL.MUDD..>> GOOD MORNING..I JT WANT TO SAY, IF WE HAVE.CHRIS CUOMO REPRESENTING MEN IN.AMERICA, HE LOOKS LIKE A BRIDGE.TROLL, AND HE\\'S GOT THE.INTELLECT OF A TROGLODITE..>> USING THOSE BIG WORDS..>> YOU ARE REALLY ENJOYING THIS.MOMENT, PHIL..>> LOOK AT YOU LAUGHING..YOU ARE HAPPY ABOUT IT..>> WE DID ENJOY THAT LAST.SEGMENT..ALL RIGHT..LET\\'S MOVE ON TO OUR OWN.SEGMENT, PHIL..YOU WORKED AT THE FBI FOR ALMOST.FIVE YEARS..WHAT DO YOU THINK ABOUT DIRECTOR.COMEY ALERTING CONGRESS TO THIS.NEW WRINKLE IN THE INVESTIGATION.BEFORE HE KNOWS WHETHER OR NOT.THESE E-MAILS ARE RELEVANT OR.NOT RELEVANT TO HILLARY CLINTON?.>> HE CAN\\'T WIN..LET\\'S TAKE IT TO THE DAY AFTER.THE ELECTION, NEXT WEDNESDAY..LET\\'S SAY HE COMES OUT WITH AN.ANNOUNCEMENT..THERE\\'S SOME FBI PRECEDENT FOR.DOING THAT..YOU DO NOT ANNOUNCE, ESPECIALLY.IN A POLITICAL CAMPAIGN,.INVESTIGATIONS OF CANDIDATES..>> THAT IS THE TRADITION, RIGHT?.AND IT\\'S KNOWN INSIDE THE FBI.THAT YOU DON\\'T TRY TO SOMEHOW.INSERT YOURSELF IN THESE FINAL.DAYS..>> THAT\\'S RIGHT..BUT IF YOU OPEN A NEW.INVESTIGATION, I COULD SEE THAT..IN THIS CASE, WE HAVE HIM ON THE.RECORD SAYING THIS IS A CLOSED.INVESTIGATION..FAST FORWARD EIGHT DAYS..LET\\'S SAY HE COMES OUT AND SAYS,.I DIDN\\'T TELL YOU DURING THAT.CAMPAIGN THAT I CHOSE TO REOPEN.IT..THE OPPOSITE SIDE IS GOING TO.SAY, ARE YOU KIDDING ME?.YOU MISLED US BY NOT CORRECTING.THE RECORD..I DON\\'T THINK HE CAN WIN..>> DO YOU THINK THAT WHATEVER.E-MAILS ARE ON ANTHONY WEINER\\'S.LAB TOP THAT ARE CONNECTED TO.HUMA ABEDIN, DO YOU THINK WE\\'RE.GOING TO FIND SOMETHING NEW?.>> HECK NO..I DON\\'T THINK THIS IS GOING TO.GO ANYWHERE..THERE\\'S TWO QUESTIONS HERE..WE\\'RE FOCUSED ON THE WRONG.QUESTION..WHETHER THERE\\'S MORE CLASSIFIED.INFORMATION..THE FBI DIRECTOR, WHEN HE CLOSED.THE INVESTIGATION, SAID HE.WASN\\'T CLOSE TO A PROSECUTORIAL.BAR..THAT MEANS THERE HAS TO BE.SOMETHING SUBSTANTIAL IN THE.E-MAILS..>> A BOMBSHELL..>> THAT BOMBSHELL IS NOT ABOUT.MORE CLASSIFIED INFORMATION..IT\\'S ABOUT WHETHER THERE\\'S AN.INDICATION ABOUT WHAT PEOPLE.INTENDED TO DO..DID THEY WANT TO BREAK THE LAW?.I DON\\'T THINK WE\\'LL FIND THAT..>> SO MANY PEOPLE SAY IF THIS.WERE ANYBODY BUT HILLARY.CLINTON, THIS PERSON WOULD BE IN.JAIL OR THIS PERSON WOULD BE.PROSECUTED OR THIS PERSON WOULD.LOSE THEIR JOB..DO YOU THINK THERE\\'S BEEN A.DIFFERENT STANDARD FOR THE.MATERIAL THAT WAS FOUND ON HER.PERSONAL SERVER THAN THERE WOULD.BE FOR ANYBODY ELSE?.>> NO, I SERVED IN THE.GOVERNMENT FOR 25 YEARS..I WATCHED INVESTIGATIONS LIKE.THIS..I LOOK AT THIS THROUGH THE LENS.OF WHAT WOULD HAVE HAPPENED TO.ME OR SOMEBODY WORKING FOR ME..I THINK THERE\\'S A MINIMUM THAT.WOULD HAVE HAPPENED..YOU\\'RE SUSPENDED WITHOUT PAY FOR.30 DAYS..I THINK THAT\\'S TOO LIGHT..I SUSPECT WHAT WOULD HAVE.HAPPENED HERE IS A MIDDLE GROUND.BETWEEN SUSPENSION AND.PROSECUTION..>> SO YOU THINK A MINI DOUBLE.STANDARD..>> I DON\\'T THINK SHE\\'LL BE.PROSECUTED EITHER..I THINK THE FBI HAS TO.INVESTIGATE, BUT THEY\\'RE GOING.TO FIND OUT THE SAME THING.COMEY\\'S ALREADY SAID..THIS IS BAD JUDGMENT..IT IS NOT NEAR THE LEVEL OF.PROSECUTION..>> OKAY.WHILE WE HAVE YOU HERE, WE WANT.TO TALK ABOUT THESE NEW.AUDIOTAPES THAT WERE RELEASED.JUST YESTERDAY ABOUT THE.TERRORISTS AT THE ORLANDO PULSE.NIGHTCLUB..FOR THE FIRST TIME, WE HEAR HIM.NEGOTIATING WITH A HOSTAGE.NEGOTIATOR WHO\\'S TRYING TO.OBVIOUSLY TRY TO DIFFUSE THE.SITUATION..IT\\'S VERY DISTURBING, BUT LISTEN.TO THIS AUDIOTAPE..>> CAN YOU TELL ME WHAT YOU KNOW.ABOUT WHAT\\'S GOING ON TONIGHT?.>> WHAT\\'S GOING ON IS THAT I.FEEL THE PAIN OF THE PEOPLE.GETTING KILLED IN SYRIA AND IRAQ.AND ALL OVER THE MUSLIM --.>> OKAY..SO HAVE YOU DONE SOMETHING ABOUT.THAT?.>> YES, I HAVE..>> TELL ME WHAT YOU DID, PLEASE..>> NO, YOU ALREADY KNOW WHAT I.DID..>> I\\'M TRYING TO OFFER YOU HELP..>> WELL, YOU NEED TO KNOW THAT.THEY NEED TO STOP BOMBING SYRIA.AND IRAQ..THE U.S. IS COLLABORATING WITH.RUSSIA, AND THEY\\'RE KILLING.INNOCENT WOMEN AND CHILDREN,.OKAY?.>> I HEAR WHAT YOU\\'RE SAYING..>> MY HOME BOY TSARNAEV DID HIS.THING ON THE BOSTON MARATHON..MY HOME BOY DID HIS THING..OKAY..SO NOW IT\\'S MY TURN..>> OKAY..>> SO YOU HEAR HIS TWISTED LOGIC.THERE..THEY\\'RE KILLING WOMEN AND.CHILDREN, SO I CAN MOW DOWN.PEOPLE AND KILL WHOEVER I WANT..AS A COUNTERTERRORISM OFFICIAL,.WHAT DO YOU HEAR IN THIS.CONFESSION?.>> WELL, I HEAR A COUPLE THINGS..THE PRIMARY THING IS.JUSTIFICATION..THERE IS NO JUSTIFICATION IN.ISLAM FOR THE KILLING OF.INNOCENTS..HE\\'S TRYING TO SAY THIS IS A.BATTLE AND I\\'M A WARRIOR IN THE.BATTLE..WHAT YOU\\'RE HEARING IS BOTH WHY.ISIS SUCCEEDS IN RECRUITING..IT\\'S ALSO THE CORE OF WHY THEY.WILL FAIL AND WHY AL QAEDA.FAILED, WHY THE FUTURE ISIS.ORGANIZATIONS WILL FAIL..THEY CAN\\'T GET OVER THE BAR OF.EXPLAINING WHY THE MURDER OF.INNOCENTS IS ACCEPTABLE..AND I DON\\'T THINK HIS.EXPLANATION WILL HOLD WATER WITH.99.9% OF PEOPLE IN THE ISLAMIC.WORLD..>> PHIL MUDD, THANK YOU..>>> WE\\'RE FOLLOWING A LOT OF.NEWS THIS MORNING..WE\\'LL TALK WITH HILLARY.CLINTON\\'S CAMPAIGN MANAGER SOON..LET\\'S GET RIGHT TO IT..>>> HOW CAN HILLARY MANAGE THIS.COUNTRY IF HE CAN\\'T EVEN MANAGE.HER E-MAILS?.>> IF THEY WANT TO LOOK AT MORE.E-MAILS, GO AHEAD..LOOK AT THEM..>> IT\\'S IMPOSSIBLE TO VIEW THIS.AS ANYTHING LESS THAN A BLATANT.DOUBLE STANDARD..>> THE CONTROVERSIAL PRO-TRUMP.ROBO CALL..>> I BELIEVE EVAN IS A CLOSET'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "json_data[\"context\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ey9YvUogomjT"
      },
      "outputs": [],
      "source": [
        "ds = Dataset.from_dict(json_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDX0pvvbtn2l",
        "outputId": "881eaaff-0cd0-4f80-bbae-80ae8c884ddd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.33)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzkyJZWj0kED",
        "outputId": "e4133ae7-a8f4-408a-806d-299c4d4d69de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lan': 'ENG', 'src': 'UCLA Library', 'dur': '0:59:53.76', 'col': 'Communication Studies Archive, UCLA', 'path': '2016-11-01_1000_US_CNN_New_Day.txt'}\n",
            "<class 'str'>\n",
            "{'lan': 'ENG', 'src': 'UCLA Library', 'dur': '00:59:54', 'col': 'Communication Studies Archive, UCLA', 'path': '2016-11-17_0300_US_FOX-News_Hannity.txt'}\n",
            "<class 'str'>\n",
            "{'lan': 'ENG', 'src': 'UCLA Library', 'dur': '0:59:53.52', 'col': 'Communication Studies Archive, UCLA', 'path': '2016-11-04_0000_US_KNBC_KNBC_4_News_at_5pm.txt'}\n",
            "<class 'str'>\n",
            "{'lan': 'ENG', 'src': 'UCLA Library', 'dur': '0:34:53.48', 'col': 'Communication Studies Archive, UCLA', 'path': '2016-11-10_0700_US_KNBC_Channel_4_News_at_11PM.txt'}\n",
            "<class 'str'>\n",
            "{'lan': 'ENG', 'src': '5 WEWSDT OH61161', 'dur': '00:29:52', 'col': 'Communication Studies Archive, UCLA', 'path': '2016-11-20_2300_US_WEWS_News_5_at_6pm.txt'}\n",
            "<class 'str'>\n",
            "{'lan': 'ENG', 'src': 'UCLA Library', 'dur': '0:59:54.54', 'col': 'Communication Studies Archive, UCLA', 'path': '2016-11-08_0837_US_KNBC_Late_Night_With_Seth_Meyers.txt'}\n",
            "<class 'str'>\n",
            "{'lan': 'ENG', 'src': 'UCLA Library', 'dur': '0:59:53.54', 'col': 'Communication Studies Archive, UCLA', 'path': '2016-11-09_1200_US_FOX-News_Fox_and_Friends.txt'}\n",
            "<class 'str'>\n",
            "{'lan': 'ENG', 'src': 'UCLA Library', 'dur': '0:59:53.50', 'col': 'Communication Studies Archive, UCLA', 'path': '2016-11-08_0200_US_CNN_Anderson_Cooper_360.txt'}\n",
            "<class 'str'>\n",
            "{'lan': 'ENG', 'src': 'UCLA Library', 'dur': '0:59:54.76', 'col': 'Communication Studies Archive, UCLA', 'path': '2016-11-02_2100_US_CNN_Situation_Room.txt'}\n",
            "<class 'str'>\n",
            "{'lan': 'ENG', 'src': 'UCLA Library', 'dur': '0:59:54.86', 'col': 'Communication Studies Archive, UCLA', 'path': '2016-11-17_0200_US_CNN_CNN_Reports.txt'}\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "for i in ds[\"metadata\"][:10]:\n",
        "  print(i)\n",
        "  print(type(i))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "Q5ma-6BKIQwd",
        "outputId": "45910d8b-e671-43d1-dd5e-5a801bcb6b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'int' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-13becb3fb924>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentence-transformers/all-MiniLM-L6-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = model.encode(ds[0][\"context\"])\n",
        "print(encoded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDz1_1ZCJRjl",
        "outputId": "1b36d9c3-f132-4f5c-9f22-2ca3995734d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(384,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Xii2IkCrqHe1"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "import uuid\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TextProcessor :\n",
        "  def __init__(self , dataset : Dataset) :\n",
        "    self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=500,\n",
        "            chunk_overlap=50,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
        "        )\n",
        "\n",
        "    self.dataset = dataset\n",
        "\n",
        "  def process_text(self):\n",
        "    Documents = []\n",
        "    i = 0\n",
        "    for context , metadata in zip(self.dataset[\"context\"] , self.dataset[\"metadata\"]):\n",
        "      chunks = self.text_splitter.split_text(context)\n",
        "      for chunk in chunks :\n",
        "\n",
        "        if isinstance(metadata , str) :\n",
        "          try :\n",
        "            metadata = json.loads(metadata)\n",
        "          except json.JSONDecodeError :\n",
        "            metadata = {}\n",
        "        doc = Document(page_content = self.clean_text(chunk),\n",
        "                       metadata = {\n",
        "                        **metadata,\n",
        "                        'chunk_id': str(uuid.uuid4()),\n",
        "                        'timestamp': datetime.now().isoformat()\n",
        "                    })\n",
        "        Documents.append(doc)\n",
        "    return Documents\n",
        "\n",
        "  def clean_text(self , text ) :\n",
        "     # Removes excessive punctuation and fix spacing\n",
        "    cleaned = re.sub(r'\\.+', '.', text)  # Removes multiple periods\n",
        "    cleaned = re.sub(r'>>', '', cleaned)  # Removes '>>' markers\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned)  # Fix multiple spaces\n",
        "\n",
        "    # Fix sentence boundaries\n",
        "    cleaned = cleaned.replace('.', '. ')\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
        "    cleaned = cleaned.lower()\n",
        "    sentences = [s.strip().capitalize() for s in cleaned.split('.') if s.strip()]\n",
        "    text = \". \".join(sentences)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_community"
      ],
      "metadata": {
        "id": "Q2-LY5vdL4il"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  fastembed\n",
        "!pip install -q chromadb\n"
      ],
      "metadata": {
        "id": "BR0GV5dNMEp_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_ds = ds.select(range(100))\n",
        "small_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgE06pkHeDKB",
        "outputId": "c2f454f4-50c0-46de-d477-8e38b8534444"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['context', 'metadata'],\n",
              "    num_rows: 100\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######embedding///////////////////////////////////\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "class EmbeddingGeneration :\n",
        "\n",
        "  def __init__(self , collection_dir : str , chromadb_val : bool = True , Qdrant : bool = False) -> None:\n",
        "\n",
        "    if Qdrant :\n",
        "        self.embeddingModel =  FastEmbedEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "    self.embeddingModel = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "    model_name=\"all-MiniLM-L12-v2\"\n",
        "    )\n",
        "    self.collection_dir = collection_dir\n",
        "\n",
        "\n",
        "    self.embeddingClient = chromadb.PersistentClient( path=self.collection_dir,\n",
        "            settings=chromadb.Settings(\n",
        "                allow_reset=True,\n",
        "                is_persistent=True\n",
        "            ))\n",
        "\n",
        "\n",
        "  def create_collection(self , collection_name : str) :\n",
        "    try :\n",
        "\n",
        "      if collection_name in self.embeddingClient.list_collections():\n",
        "        self.collection = self.embeddingClient.get_collection(name=collection_name)\n",
        "        return self.collection\n",
        "\n",
        "      self.collection = self.embeddingClient.get_or_create_collection(name=collection_name\n",
        "            , embedding_function = self.embeddingModel)\n",
        "      return self.collection\n",
        "\n",
        "    except Exception as e :\n",
        "      print(\"error : \" , e )\n",
        "      raise\n",
        "\n",
        "  def generate_embeddings(self , documents : List[Document] , batch_size : int = 40):\n",
        "    try :\n",
        "      collection = self.create_collection(\"News-embedds\")\n",
        "      print(collection)\n",
        "      print(collection)\n",
        "      for i in range(0 , len(documents) , batch_size):\n",
        "        endidx = min(len(documents) , i+batch_size)\n",
        "        docs = documents[i:endidx]\n",
        "        ids = [doc.metadata['chunk_id'] for doc in docs]\n",
        "        texts = [doc.page_content for doc in docs]\n",
        "        print(f\"generating embeddings for {i} => {i+batch_size}\")\n",
        "        embeddings = self.embeddingModel(texts)\n",
        "        print(f\"embeddings generated for {i} => {i+batch_size}\")\n",
        "        collection.add(documents=texts ,embeddings = embeddings,ids=ids)\n",
        "        print(f\"documents {i} => {i+batch_size} added to collection\")\n",
        "      return True\n",
        "\n",
        "    except Exception as e :\n",
        "      print(f\"error : {e}\")\n",
        "      return False\n",
        "\n"
      ],
      "metadata": {
        "id": "Srh6nf6iLblh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhUYXphT0MkT",
        "outputId": "07e7d8a0-dc23-4975-e4c8-388133dbd8a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8552"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "path = os.path.abspath(\"/embed-engine\")\n",
        "\n",
        "\n",
        "embed_agent = EmbeddingGeneration(collection_dir=path)\n",
        "docs = TextProcessor(small_ds).process_text()\n",
        "len(docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_agent.generate_embeddings(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8vyh1kNmkcn7",
        "outputId": "17e8fe21-76a2-43b7-a2e4-bf7befb1d370"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection(name=News-embedds)\n",
            "Collection(name=News-embedds)\n",
            "generating embeddings for 0 => 40\n",
            "embeddings generated for 0 => 40\n",
            "documents 0 => 40 added to collection\n",
            "generating embeddings for 40 => 80\n",
            "embeddings generated for 40 => 80\n",
            "documents 40 => 80 added to collection\n",
            "generating embeddings for 80 => 120\n",
            "embeddings generated for 80 => 120\n",
            "documents 80 => 120 added to collection\n",
            "generating embeddings for 120 => 160\n",
            "embeddings generated for 120 => 160\n",
            "documents 120 => 160 added to collection\n",
            "generating embeddings for 160 => 200\n",
            "embeddings generated for 160 => 200\n",
            "documents 160 => 200 added to collection\n",
            "generating embeddings for 200 => 240\n",
            "embeddings generated for 200 => 240\n",
            "documents 200 => 240 added to collection\n",
            "generating embeddings for 240 => 280\n",
            "embeddings generated for 240 => 280\n",
            "documents 240 => 280 added to collection\n",
            "generating embeddings for 280 => 320\n",
            "embeddings generated for 280 => 320\n",
            "documents 280 => 320 added to collection\n",
            "generating embeddings for 320 => 360\n",
            "embeddings generated for 320 => 360\n",
            "documents 320 => 360 added to collection\n",
            "generating embeddings for 360 => 400\n",
            "embeddings generated for 360 => 400\n",
            "documents 360 => 400 added to collection\n",
            "generating embeddings for 400 => 440\n",
            "embeddings generated for 400 => 440\n",
            "documents 400 => 440 added to collection\n",
            "generating embeddings for 440 => 480\n",
            "embeddings generated for 440 => 480\n",
            "documents 440 => 480 added to collection\n",
            "generating embeddings for 480 => 520\n",
            "embeddings generated for 480 => 520\n",
            "documents 480 => 520 added to collection\n",
            "generating embeddings for 520 => 560\n",
            "embeddings generated for 520 => 560\n",
            "documents 520 => 560 added to collection\n",
            "generating embeddings for 560 => 600\n",
            "embeddings generated for 560 => 600\n",
            "documents 560 => 600 added to collection\n",
            "generating embeddings for 600 => 640\n",
            "embeddings generated for 600 => 640\n",
            "documents 600 => 640 added to collection\n",
            "generating embeddings for 640 => 680\n",
            "embeddings generated for 640 => 680\n",
            "documents 640 => 680 added to collection\n",
            "generating embeddings for 680 => 720\n",
            "embeddings generated for 680 => 720\n",
            "documents 680 => 720 added to collection\n",
            "generating embeddings for 720 => 760\n",
            "embeddings generated for 720 => 760\n",
            "documents 720 => 760 added to collection\n",
            "generating embeddings for 760 => 800\n",
            "embeddings generated for 760 => 800\n",
            "documents 760 => 800 added to collection\n",
            "generating embeddings for 800 => 840\n",
            "embeddings generated for 800 => 840\n",
            "documents 800 => 840 added to collection\n",
            "generating embeddings for 840 => 880\n",
            "embeddings generated for 840 => 880\n",
            "documents 840 => 880 added to collection\n",
            "generating embeddings for 880 => 920\n",
            "embeddings generated for 880 => 920\n",
            "documents 880 => 920 added to collection\n",
            "generating embeddings for 920 => 960\n",
            "embeddings generated for 920 => 960\n",
            "documents 920 => 960 added to collection\n",
            "generating embeddings for 960 => 1000\n",
            "embeddings generated for 960 => 1000\n",
            "documents 960 => 1000 added to collection\n",
            "generating embeddings for 1000 => 1040\n",
            "embeddings generated for 1000 => 1040\n",
            "documents 1000 => 1040 added to collection\n",
            "generating embeddings for 1040 => 1080\n",
            "embeddings generated for 1040 => 1080\n",
            "documents 1040 => 1080 added to collection\n",
            "generating embeddings for 1080 => 1120\n",
            "embeddings generated for 1080 => 1120\n",
            "documents 1080 => 1120 added to collection\n",
            "generating embeddings for 1120 => 1160\n",
            "embeddings generated for 1120 => 1160\n",
            "documents 1120 => 1160 added to collection\n",
            "generating embeddings for 1160 => 1200\n",
            "embeddings generated for 1160 => 1200\n",
            "documents 1160 => 1200 added to collection\n",
            "generating embeddings for 1200 => 1240\n",
            "embeddings generated for 1200 => 1240\n",
            "documents 1200 => 1240 added to collection\n",
            "generating embeddings for 1240 => 1280\n",
            "embeddings generated for 1240 => 1280\n",
            "documents 1240 => 1280 added to collection\n",
            "generating embeddings for 1280 => 1320\n",
            "embeddings generated for 1280 => 1320\n",
            "documents 1280 => 1320 added to collection\n",
            "generating embeddings for 1320 => 1360\n",
            "embeddings generated for 1320 => 1360\n",
            "documents 1320 => 1360 added to collection\n",
            "generating embeddings for 1360 => 1400\n",
            "embeddings generated for 1360 => 1400\n",
            "documents 1360 => 1400 added to collection\n",
            "generating embeddings for 1400 => 1440\n",
            "embeddings generated for 1400 => 1440\n",
            "documents 1400 => 1440 added to collection\n",
            "generating embeddings for 1440 => 1480\n",
            "embeddings generated for 1440 => 1480\n",
            "documents 1440 => 1480 added to collection\n",
            "generating embeddings for 1480 => 1520\n",
            "embeddings generated for 1480 => 1520\n",
            "documents 1480 => 1520 added to collection\n",
            "generating embeddings for 1520 => 1560\n",
            "embeddings generated for 1520 => 1560\n",
            "documents 1520 => 1560 added to collection\n",
            "generating embeddings for 1560 => 1600\n",
            "embeddings generated for 1560 => 1600\n",
            "documents 1560 => 1600 added to collection\n",
            "generating embeddings for 1600 => 1640\n",
            "embeddings generated for 1600 => 1640\n",
            "documents 1600 => 1640 added to collection\n",
            "generating embeddings for 1640 => 1680\n",
            "embeddings generated for 1640 => 1680\n",
            "documents 1640 => 1680 added to collection\n",
            "generating embeddings for 1680 => 1720\n",
            "embeddings generated for 1680 => 1720\n",
            "documents 1680 => 1720 added to collection\n",
            "generating embeddings for 1720 => 1760\n",
            "embeddings generated for 1720 => 1760\n",
            "documents 1720 => 1760 added to collection\n",
            "generating embeddings for 1760 => 1800\n",
            "embeddings generated for 1760 => 1800\n",
            "documents 1760 => 1800 added to collection\n",
            "generating embeddings for 1800 => 1840\n",
            "embeddings generated for 1800 => 1840\n",
            "documents 1800 => 1840 added to collection\n",
            "generating embeddings for 1840 => 1880\n",
            "embeddings generated for 1840 => 1880\n",
            "documents 1840 => 1880 added to collection\n",
            "generating embeddings for 1880 => 1920\n",
            "embeddings generated for 1880 => 1920\n",
            "documents 1880 => 1920 added to collection\n",
            "generating embeddings for 1920 => 1960\n",
            "embeddings generated for 1920 => 1960\n",
            "documents 1920 => 1960 added to collection\n",
            "generating embeddings for 1960 => 2000\n",
            "embeddings generated for 1960 => 2000\n",
            "documents 1960 => 2000 added to collection\n",
            "generating embeddings for 2000 => 2040\n",
            "embeddings generated for 2000 => 2040\n",
            "documents 2000 => 2040 added to collection\n",
            "generating embeddings for 2040 => 2080\n",
            "embeddings generated for 2040 => 2080\n",
            "documents 2040 => 2080 added to collection\n",
            "generating embeddings for 2080 => 2120\n",
            "embeddings generated for 2080 => 2120\n",
            "documents 2080 => 2120 added to collection\n",
            "generating embeddings for 2120 => 2160\n",
            "embeddings generated for 2120 => 2160\n",
            "documents 2120 => 2160 added to collection\n",
            "generating embeddings for 2160 => 2200\n",
            "embeddings generated for 2160 => 2200\n",
            "documents 2160 => 2200 added to collection\n",
            "generating embeddings for 2200 => 2240\n",
            "embeddings generated for 2200 => 2240\n",
            "documents 2200 => 2240 added to collection\n",
            "generating embeddings for 2240 => 2280\n",
            "embeddings generated for 2240 => 2280\n",
            "documents 2240 => 2280 added to collection\n",
            "generating embeddings for 2280 => 2320\n",
            "embeddings generated for 2280 => 2320\n",
            "documents 2280 => 2320 added to collection\n",
            "generating embeddings for 2320 => 2360\n",
            "embeddings generated for 2320 => 2360\n",
            "documents 2320 => 2360 added to collection\n",
            "generating embeddings for 2360 => 2400\n",
            "embeddings generated for 2360 => 2400\n",
            "documents 2360 => 2400 added to collection\n",
            "generating embeddings for 2400 => 2440\n",
            "embeddings generated for 2400 => 2440\n",
            "documents 2400 => 2440 added to collection\n",
            "generating embeddings for 2440 => 2480\n",
            "embeddings generated for 2440 => 2480\n",
            "documents 2440 => 2480 added to collection\n",
            "generating embeddings for 2480 => 2520\n",
            "embeddings generated for 2480 => 2520\n",
            "documents 2480 => 2520 added to collection\n",
            "generating embeddings for 2520 => 2560\n",
            "embeddings generated for 2520 => 2560\n",
            "documents 2520 => 2560 added to collection\n",
            "generating embeddings for 2560 => 2600\n",
            "embeddings generated for 2560 => 2600\n",
            "documents 2560 => 2600 added to collection\n",
            "generating embeddings for 2600 => 2640\n",
            "embeddings generated for 2600 => 2640\n",
            "documents 2600 => 2640 added to collection\n",
            "generating embeddings for 2640 => 2680\n",
            "embeddings generated for 2640 => 2680\n",
            "documents 2640 => 2680 added to collection\n",
            "generating embeddings for 2680 => 2720\n",
            "embeddings generated for 2680 => 2720\n",
            "documents 2680 => 2720 added to collection\n",
            "generating embeddings for 2720 => 2760\n",
            "embeddings generated for 2720 => 2760\n",
            "documents 2720 => 2760 added to collection\n",
            "generating embeddings for 2760 => 2800\n",
            "embeddings generated for 2760 => 2800\n",
            "documents 2760 => 2800 added to collection\n",
            "generating embeddings for 2800 => 2840\n",
            "embeddings generated for 2800 => 2840\n",
            "documents 2800 => 2840 added to collection\n",
            "generating embeddings for 2840 => 2880\n",
            "embeddings generated for 2840 => 2880\n",
            "documents 2840 => 2880 added to collection\n",
            "generating embeddings for 2880 => 2920\n",
            "embeddings generated for 2880 => 2920\n",
            "documents 2880 => 2920 added to collection\n",
            "generating embeddings for 2920 => 2960\n",
            "embeddings generated for 2920 => 2960\n",
            "documents 2920 => 2960 added to collection\n",
            "generating embeddings for 2960 => 3000\n",
            "embeddings generated for 2960 => 3000\n",
            "documents 2960 => 3000 added to collection\n",
            "generating embeddings for 3000 => 3040\n",
            "embeddings generated for 3000 => 3040\n",
            "documents 3000 => 3040 added to collection\n",
            "generating embeddings for 3040 => 3080\n",
            "embeddings generated for 3040 => 3080\n",
            "documents 3040 => 3080 added to collection\n",
            "generating embeddings for 3080 => 3120\n",
            "embeddings generated for 3080 => 3120\n",
            "documents 3080 => 3120 added to collection\n",
            "generating embeddings for 3120 => 3160\n",
            "embeddings generated for 3120 => 3160\n",
            "documents 3120 => 3160 added to collection\n",
            "generating embeddings for 3160 => 3200\n",
            "embeddings generated for 3160 => 3200\n",
            "documents 3160 => 3200 added to collection\n",
            "generating embeddings for 3200 => 3240\n",
            "embeddings generated for 3200 => 3240\n",
            "documents 3200 => 3240 added to collection\n",
            "generating embeddings for 3240 => 3280\n",
            "embeddings generated for 3240 => 3280\n",
            "documents 3240 => 3280 added to collection\n",
            "generating embeddings for 3280 => 3320\n",
            "embeddings generated for 3280 => 3320\n",
            "documents 3280 => 3320 added to collection\n",
            "generating embeddings for 3320 => 3360\n",
            "embeddings generated for 3320 => 3360\n",
            "documents 3320 => 3360 added to collection\n",
            "generating embeddings for 3360 => 3400\n",
            "embeddings generated for 3360 => 3400\n",
            "documents 3360 => 3400 added to collection\n",
            "generating embeddings for 3400 => 3440\n",
            "embeddings generated for 3400 => 3440\n",
            "documents 3400 => 3440 added to collection\n",
            "generating embeddings for 3440 => 3480\n",
            "embeddings generated for 3440 => 3480\n",
            "documents 3440 => 3480 added to collection\n",
            "generating embeddings for 3480 => 3520\n",
            "embeddings generated for 3480 => 3520\n",
            "documents 3480 => 3520 added to collection\n",
            "generating embeddings for 3520 => 3560\n",
            "embeddings generated for 3520 => 3560\n",
            "documents 3520 => 3560 added to collection\n",
            "generating embeddings for 3560 => 3600\n",
            "embeddings generated for 3560 => 3600\n",
            "documents 3560 => 3600 added to collection\n",
            "generating embeddings for 3600 => 3640\n",
            "embeddings generated for 3600 => 3640\n",
            "documents 3600 => 3640 added to collection\n",
            "generating embeddings for 3640 => 3680\n",
            "embeddings generated for 3640 => 3680\n",
            "documents 3640 => 3680 added to collection\n",
            "generating embeddings for 3680 => 3720\n",
            "embeddings generated for 3680 => 3720\n",
            "documents 3680 => 3720 added to collection\n",
            "generating embeddings for 3720 => 3760\n",
            "embeddings generated for 3720 => 3760\n",
            "documents 3720 => 3760 added to collection\n",
            "generating embeddings for 3760 => 3800\n",
            "embeddings generated for 3760 => 3800\n",
            "documents 3760 => 3800 added to collection\n",
            "generating embeddings for 3800 => 3840\n",
            "embeddings generated for 3800 => 3840\n",
            "documents 3800 => 3840 added to collection\n",
            "generating embeddings for 3840 => 3880\n",
            "embeddings generated for 3840 => 3880\n",
            "documents 3840 => 3880 added to collection\n",
            "generating embeddings for 3880 => 3920\n",
            "embeddings generated for 3880 => 3920\n",
            "documents 3880 => 3920 added to collection\n",
            "generating embeddings for 3920 => 3960\n",
            "embeddings generated for 3920 => 3960\n",
            "documents 3920 => 3960 added to collection\n",
            "generating embeddings for 3960 => 4000\n",
            "embeddings generated for 3960 => 4000\n",
            "documents 3960 => 4000 added to collection\n",
            "generating embeddings for 4000 => 4040\n",
            "embeddings generated for 4000 => 4040\n",
            "documents 4000 => 4040 added to collection\n",
            "generating embeddings for 4040 => 4080\n",
            "embeddings generated for 4040 => 4080\n",
            "documents 4040 => 4080 added to collection\n",
            "generating embeddings for 4080 => 4120\n",
            "embeddings generated for 4080 => 4120\n",
            "documents 4080 => 4120 added to collection\n",
            "generating embeddings for 4120 => 4160\n",
            "embeddings generated for 4120 => 4160\n",
            "documents 4120 => 4160 added to collection\n",
            "generating embeddings for 4160 => 4200\n",
            "embeddings generated for 4160 => 4200\n",
            "documents 4160 => 4200 added to collection\n",
            "generating embeddings for 4200 => 4240\n",
            "embeddings generated for 4200 => 4240\n",
            "documents 4200 => 4240 added to collection\n",
            "generating embeddings for 4240 => 4280\n",
            "embeddings generated for 4240 => 4280\n",
            "documents 4240 => 4280 added to collection\n",
            "generating embeddings for 4280 => 4320\n",
            "embeddings generated for 4280 => 4320\n",
            "documents 4280 => 4320 added to collection\n",
            "generating embeddings for 4320 => 4360\n",
            "embeddings generated for 4320 => 4360\n",
            "documents 4320 => 4360 added to collection\n",
            "generating embeddings for 4360 => 4400\n",
            "embeddings generated for 4360 => 4400\n",
            "documents 4360 => 4400 added to collection\n",
            "generating embeddings for 4400 => 4440\n",
            "embeddings generated for 4400 => 4440\n",
            "documents 4400 => 4440 added to collection\n",
            "generating embeddings for 4440 => 4480\n",
            "embeddings generated for 4440 => 4480\n",
            "documents 4440 => 4480 added to collection\n",
            "generating embeddings for 4480 => 4520\n",
            "embeddings generated for 4480 => 4520\n",
            "documents 4480 => 4520 added to collection\n",
            "generating embeddings for 4520 => 4560\n",
            "embeddings generated for 4520 => 4560\n",
            "documents 4520 => 4560 added to collection\n",
            "generating embeddings for 4560 => 4600\n",
            "embeddings generated for 4560 => 4600\n",
            "documents 4560 => 4600 added to collection\n",
            "generating embeddings for 4600 => 4640\n",
            "embeddings generated for 4600 => 4640\n",
            "documents 4600 => 4640 added to collection\n",
            "generating embeddings for 4640 => 4680\n",
            "embeddings generated for 4640 => 4680\n",
            "documents 4640 => 4680 added to collection\n",
            "generating embeddings for 4680 => 4720\n",
            "embeddings generated for 4680 => 4720\n",
            "documents 4680 => 4720 added to collection\n",
            "generating embeddings for 4720 => 4760\n",
            "embeddings generated for 4720 => 4760\n",
            "documents 4720 => 4760 added to collection\n",
            "generating embeddings for 4760 => 4800\n",
            "embeddings generated for 4760 => 4800\n",
            "documents 4760 => 4800 added to collection\n",
            "generating embeddings for 4800 => 4840\n",
            "embeddings generated for 4800 => 4840\n",
            "documents 4800 => 4840 added to collection\n",
            "generating embeddings for 4840 => 4880\n",
            "embeddings generated for 4840 => 4880\n",
            "documents 4840 => 4880 added to collection\n",
            "generating embeddings for 4880 => 4920\n",
            "embeddings generated for 4880 => 4920\n",
            "documents 4880 => 4920 added to collection\n",
            "generating embeddings for 4920 => 4960\n",
            "embeddings generated for 4920 => 4960\n",
            "documents 4920 => 4960 added to collection\n",
            "generating embeddings for 4960 => 5000\n",
            "embeddings generated for 4960 => 5000\n",
            "documents 4960 => 5000 added to collection\n",
            "generating embeddings for 5000 => 5040\n",
            "embeddings generated for 5000 => 5040\n",
            "documents 5000 => 5040 added to collection\n",
            "generating embeddings for 5040 => 5080\n",
            "embeddings generated for 5040 => 5080\n",
            "documents 5040 => 5080 added to collection\n",
            "generating embeddings for 5080 => 5120\n",
            "embeddings generated for 5080 => 5120\n",
            "documents 5080 => 5120 added to collection\n",
            "generating embeddings for 5120 => 5160\n",
            "embeddings generated for 5120 => 5160\n",
            "documents 5120 => 5160 added to collection\n",
            "generating embeddings for 5160 => 5200\n",
            "embeddings generated for 5160 => 5200\n",
            "documents 5160 => 5200 added to collection\n",
            "generating embeddings for 5200 => 5240\n",
            "embeddings generated for 5200 => 5240\n",
            "documents 5200 => 5240 added to collection\n",
            "generating embeddings for 5240 => 5280\n",
            "embeddings generated for 5240 => 5280\n",
            "documents 5240 => 5280 added to collection\n",
            "generating embeddings for 5280 => 5320\n",
            "embeddings generated for 5280 => 5320\n",
            "documents 5280 => 5320 added to collection\n",
            "generating embeddings for 5320 => 5360\n",
            "embeddings generated for 5320 => 5360\n",
            "documents 5320 => 5360 added to collection\n",
            "generating embeddings for 5360 => 5400\n",
            "embeddings generated for 5360 => 5400\n",
            "documents 5360 => 5400 added to collection\n",
            "generating embeddings for 5400 => 5440\n",
            "embeddings generated for 5400 => 5440\n",
            "documents 5400 => 5440 added to collection\n",
            "generating embeddings for 5440 => 5480\n",
            "embeddings generated for 5440 => 5480\n",
            "documents 5440 => 5480 added to collection\n",
            "generating embeddings for 5480 => 5520\n",
            "embeddings generated for 5480 => 5520\n",
            "documents 5480 => 5520 added to collection\n",
            "generating embeddings for 5520 => 5560\n",
            "embeddings generated for 5520 => 5560\n",
            "documents 5520 => 5560 added to collection\n",
            "generating embeddings for 5560 => 5600\n",
            "embeddings generated for 5560 => 5600\n",
            "documents 5560 => 5600 added to collection\n",
            "generating embeddings for 5600 => 5640\n",
            "embeddings generated for 5600 => 5640\n",
            "documents 5600 => 5640 added to collection\n",
            "generating embeddings for 5640 => 5680\n",
            "embeddings generated for 5640 => 5680\n",
            "documents 5640 => 5680 added to collection\n",
            "generating embeddings for 5680 => 5720\n",
            "embeddings generated for 5680 => 5720\n",
            "documents 5680 => 5720 added to collection\n",
            "generating embeddings for 5720 => 5760\n",
            "embeddings generated for 5720 => 5760\n",
            "documents 5720 => 5760 added to collection\n",
            "generating embeddings for 5760 => 5800\n",
            "embeddings generated for 5760 => 5800\n",
            "documents 5760 => 5800 added to collection\n",
            "generating embeddings for 5800 => 5840\n",
            "embeddings generated for 5800 => 5840\n",
            "documents 5800 => 5840 added to collection\n",
            "generating embeddings for 5840 => 5880\n",
            "embeddings generated for 5840 => 5880\n",
            "documents 5840 => 5880 added to collection\n",
            "generating embeddings for 5880 => 5920\n",
            "embeddings generated for 5880 => 5920\n",
            "documents 5880 => 5920 added to collection\n",
            "generating embeddings for 5920 => 5960\n",
            "embeddings generated for 5920 => 5960\n",
            "documents 5920 => 5960 added to collection\n",
            "generating embeddings for 5960 => 6000\n",
            "embeddings generated for 5960 => 6000\n",
            "documents 5960 => 6000 added to collection\n",
            "generating embeddings for 6000 => 6040\n",
            "embeddings generated for 6000 => 6040\n",
            "documents 6000 => 6040 added to collection\n",
            "generating embeddings for 6040 => 6080\n",
            "embeddings generated for 6040 => 6080\n",
            "documents 6040 => 6080 added to collection\n",
            "generating embeddings for 6080 => 6120\n",
            "embeddings generated for 6080 => 6120\n",
            "documents 6080 => 6120 added to collection\n",
            "generating embeddings for 6120 => 6160\n",
            "embeddings generated for 6120 => 6160\n",
            "documents 6120 => 6160 added to collection\n",
            "generating embeddings for 6160 => 6200\n",
            "embeddings generated for 6160 => 6200\n",
            "documents 6160 => 6200 added to collection\n",
            "generating embeddings for 6200 => 6240\n",
            "embeddings generated for 6200 => 6240\n",
            "documents 6200 => 6240 added to collection\n",
            "generating embeddings for 6240 => 6280\n",
            "embeddings generated for 6240 => 6280\n",
            "documents 6240 => 6280 added to collection\n",
            "generating embeddings for 6280 => 6320\n",
            "embeddings generated for 6280 => 6320\n",
            "documents 6280 => 6320 added to collection\n",
            "generating embeddings for 6320 => 6360\n",
            "embeddings generated for 6320 => 6360\n",
            "documents 6320 => 6360 added to collection\n",
            "generating embeddings for 6360 => 6400\n",
            "embeddings generated for 6360 => 6400\n",
            "documents 6360 => 6400 added to collection\n",
            "generating embeddings for 6400 => 6440\n",
            "embeddings generated for 6400 => 6440\n",
            "documents 6400 => 6440 added to collection\n",
            "generating embeddings for 6440 => 6480\n",
            "embeddings generated for 6440 => 6480\n",
            "documents 6440 => 6480 added to collection\n",
            "generating embeddings for 6480 => 6520\n",
            "embeddings generated for 6480 => 6520\n",
            "documents 6480 => 6520 added to collection\n",
            "generating embeddings for 6520 => 6560\n",
            "embeddings generated for 6520 => 6560\n",
            "documents 6520 => 6560 added to collection\n",
            "generating embeddings for 6560 => 6600\n",
            "embeddings generated for 6560 => 6600\n",
            "documents 6560 => 6600 added to collection\n",
            "generating embeddings for 6600 => 6640\n",
            "embeddings generated for 6600 => 6640\n",
            "documents 6600 => 6640 added to collection\n",
            "generating embeddings for 6640 => 6680\n",
            "embeddings generated for 6640 => 6680\n",
            "documents 6640 => 6680 added to collection\n",
            "generating embeddings for 6680 => 6720\n",
            "embeddings generated for 6680 => 6720\n",
            "documents 6680 => 6720 added to collection\n",
            "generating embeddings for 6720 => 6760\n",
            "embeddings generated for 6720 => 6760\n",
            "documents 6720 => 6760 added to collection\n",
            "generating embeddings for 6760 => 6800\n",
            "embeddings generated for 6760 => 6800\n",
            "documents 6760 => 6800 added to collection\n",
            "generating embeddings for 6800 => 6840\n",
            "embeddings generated for 6800 => 6840\n",
            "documents 6800 => 6840 added to collection\n",
            "generating embeddings for 6840 => 6880\n",
            "embeddings generated for 6840 => 6880\n",
            "documents 6840 => 6880 added to collection\n",
            "generating embeddings for 6880 => 6920\n",
            "embeddings generated for 6880 => 6920\n",
            "documents 6880 => 6920 added to collection\n",
            "generating embeddings for 6920 => 6960\n",
            "embeddings generated for 6920 => 6960\n",
            "documents 6920 => 6960 added to collection\n",
            "generating embeddings for 6960 => 7000\n",
            "embeddings generated for 6960 => 7000\n",
            "documents 6960 => 7000 added to collection\n",
            "generating embeddings for 7000 => 7040\n",
            "embeddings generated for 7000 => 7040\n",
            "documents 7000 => 7040 added to collection\n",
            "generating embeddings for 7040 => 7080\n",
            "embeddings generated for 7040 => 7080\n",
            "documents 7040 => 7080 added to collection\n",
            "generating embeddings for 7080 => 7120\n",
            "embeddings generated for 7080 => 7120\n",
            "documents 7080 => 7120 added to collection\n",
            "generating embeddings for 7120 => 7160\n",
            "embeddings generated for 7120 => 7160\n",
            "documents 7120 => 7160 added to collection\n",
            "generating embeddings for 7160 => 7200\n",
            "embeddings generated for 7160 => 7200\n",
            "documents 7160 => 7200 added to collection\n",
            "generating embeddings for 7200 => 7240\n",
            "embeddings generated for 7200 => 7240\n",
            "documents 7200 => 7240 added to collection\n",
            "generating embeddings for 7240 => 7280\n",
            "embeddings generated for 7240 => 7280\n",
            "documents 7240 => 7280 added to collection\n",
            "generating embeddings for 7280 => 7320\n",
            "embeddings generated for 7280 => 7320\n",
            "documents 7280 => 7320 added to collection\n",
            "generating embeddings for 7320 => 7360\n",
            "embeddings generated for 7320 => 7360\n",
            "documents 7320 => 7360 added to collection\n",
            "generating embeddings for 7360 => 7400\n",
            "embeddings generated for 7360 => 7400\n",
            "documents 7360 => 7400 added to collection\n",
            "generating embeddings for 7400 => 7440\n",
            "embeddings generated for 7400 => 7440\n",
            "documents 7400 => 7440 added to collection\n",
            "generating embeddings for 7440 => 7480\n",
            "embeddings generated for 7440 => 7480\n",
            "documents 7440 => 7480 added to collection\n",
            "generating embeddings for 7480 => 7520\n",
            "embeddings generated for 7480 => 7520\n",
            "documents 7480 => 7520 added to collection\n",
            "generating embeddings for 7520 => 7560\n",
            "embeddings generated for 7520 => 7560\n",
            "documents 7520 => 7560 added to collection\n",
            "generating embeddings for 7560 => 7600\n",
            "embeddings generated for 7560 => 7600\n",
            "documents 7560 => 7600 added to collection\n",
            "generating embeddings for 7600 => 7640\n",
            "embeddings generated for 7600 => 7640\n",
            "documents 7600 => 7640 added to collection\n",
            "generating embeddings for 7640 => 7680\n",
            "embeddings generated for 7640 => 7680\n",
            "documents 7640 => 7680 added to collection\n",
            "generating embeddings for 7680 => 7720\n",
            "embeddings generated for 7680 => 7720\n",
            "documents 7680 => 7720 added to collection\n",
            "generating embeddings for 7720 => 7760\n",
            "embeddings generated for 7720 => 7760\n",
            "documents 7720 => 7760 added to collection\n",
            "generating embeddings for 7760 => 7800\n",
            "embeddings generated for 7760 => 7800\n",
            "documents 7760 => 7800 added to collection\n",
            "generating embeddings for 7800 => 7840\n",
            "embeddings generated for 7800 => 7840\n",
            "documents 7800 => 7840 added to collection\n",
            "generating embeddings for 7840 => 7880\n",
            "embeddings generated for 7840 => 7880\n",
            "documents 7840 => 7880 added to collection\n",
            "generating embeddings for 7880 => 7920\n",
            "embeddings generated for 7880 => 7920\n",
            "documents 7880 => 7920 added to collection\n",
            "generating embeddings for 7920 => 7960\n",
            "embeddings generated for 7920 => 7960\n",
            "documents 7920 => 7960 added to collection\n",
            "generating embeddings for 7960 => 8000\n",
            "embeddings generated for 7960 => 8000\n",
            "documents 7960 => 8000 added to collection\n",
            "generating embeddings for 8000 => 8040\n",
            "embeddings generated for 8000 => 8040\n",
            "documents 8000 => 8040 added to collection\n",
            "generating embeddings for 8040 => 8080\n",
            "embeddings generated for 8040 => 8080\n",
            "documents 8040 => 8080 added to collection\n",
            "generating embeddings for 8080 => 8120\n",
            "embeddings generated for 8080 => 8120\n",
            "documents 8080 => 8120 added to collection\n",
            "generating embeddings for 8120 => 8160\n",
            "embeddings generated for 8120 => 8160\n",
            "documents 8120 => 8160 added to collection\n",
            "generating embeddings for 8160 => 8200\n",
            "embeddings generated for 8160 => 8200\n",
            "documents 8160 => 8200 added to collection\n",
            "generating embeddings for 8200 => 8240\n",
            "embeddings generated for 8200 => 8240\n",
            "documents 8200 => 8240 added to collection\n",
            "generating embeddings for 8240 => 8280\n",
            "embeddings generated for 8240 => 8280\n",
            "documents 8240 => 8280 added to collection\n",
            "generating embeddings for 8280 => 8320\n",
            "embeddings generated for 8280 => 8320\n",
            "documents 8280 => 8320 added to collection\n",
            "generating embeddings for 8320 => 8360\n",
            "embeddings generated for 8320 => 8360\n",
            "documents 8320 => 8360 added to collection\n",
            "generating embeddings for 8360 => 8400\n",
            "embeddings generated for 8360 => 8400\n",
            "documents 8360 => 8400 added to collection\n",
            "generating embeddings for 8400 => 8440\n",
            "embeddings generated for 8400 => 8440\n",
            "documents 8400 => 8440 added to collection\n",
            "generating embeddings for 8440 => 8480\n",
            "embeddings generated for 8440 => 8480\n",
            "documents 8440 => 8480 added to collection\n",
            "generating embeddings for 8480 => 8520\n",
            "embeddings generated for 8480 => 8520\n",
            "documents 8480 => 8520 added to collection\n",
            "generating embeddings for 8520 => 8560\n",
            "embeddings generated for 8520 => 8560\n",
            "documents 8520 => 8560 added to collection\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########QUERRY//////////////\n",
        "collection = embed_agent.create_collection(\"News-embedds\")\n",
        "results = collection.query(\n",
        "    query_texts=[\"I PROMISE YOU MY BUDDY WILL.BE HERE MONDAY FOR THE DEBUT.OF TUCKER CARLSON TONIGHT..WE HAVE A LOT TO DEBUT FOR.THIS EDITION OF ON THE.RECORD\"],\n",
        "    n_results=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "MaE28BpHrgFG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpxQbPnws50b",
        "outputId": "27040eff-657c-4905-8404-8418da74548b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': [['1abe2dd5-23ea-41ba-b779-b1d666c94d7f',\n",
              "   '363e1e7e-433d-4181-a38c-a3d6551e61c9']],\n",
              " 'embeddings': None,\n",
              " 'documents': [['Get a complete update tomorrow. Morning on \"today in l. A. \". Once again, two freeways. Downtown los angeles shut down,. Protests over yesterday\\'s. Results of the election. A programming note, we had a. Special story from the i-team. Tonight. Because of the breaking news, we. Didn\\'t get to that. We\\'ll definitely bring that to. You tomorrow. We now join the \"tonight show\". With jimmy fallon from new york. [ cheers and applause ]. ♪♪. Steve: from studio 6b in. Rockefeller center in the heart',\n",
              "   \"Place. But just going down and having. To nail that cup of tea was. Tricky. It's attempted 600,000 people. Attempting a new record,. Including the shortest married. Couple on earth and the most. Magic tricks performed during a. Skydive. > coming up next, thursday. Night football returns to nbc. For the next five weeks. Tonight the panthers and saints. That's right here right now. We leave you with today's. Groundbreaking of the new rams. Stadium in inglewood. We'll see you back here for the\"]],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'metadatas': [[None, None]],\n",
              " 'distances': [[1.2157849073410034, 1.2225687503814697]],\n",
              " 'included': [<IncludeEnum.distances: 'distances'>,\n",
              "  <IncludeEnum.documents: 'documents'>,\n",
              "  <IncludeEnum.metadatas: 'metadatas'>]}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DcqPRiG83mJ"
      },
      "outputs": [],
      "source": [
        "def analyze_text_lengths(dataset):\n",
        "    lengths = []\n",
        "    sentence_counts = []\n",
        "\n",
        "    for text in dataset['context']:\n",
        "        lengths.append(len(text))\n",
        "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
        "        sentence_counts.append(len(sentences))\n",
        "    return {\n",
        "        'avg_length': sum(lengths) / len(lengths),\n",
        "        'max_length': max(lengths),\n",
        "        'min_length': min(lengths),\n",
        "        'avg_sentences': sum(sentence_counts) / len(sentence_counts)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRY6AqLh842t",
        "outputId": "e818afe4-e0d9-4dcc-d073-bb5d8b8863f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'avg_length': 38498.33,\n",
              " 'max_length': 87228,\n",
              " 'min_length': 100,\n",
              " 'avg_sentences': 1537.61}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stats = analyze_text_lengths(ds)\n",
        "stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsPTU-mC_N8_"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"You are an expert AI assistant who generates top-notch Question-Answer pairs for News conversations \\\n",
        "You are only job is to generate conversational Question-Answer pairs based on the given CONTEXT \\\n",
        "In order to generate conversational Q&A pairs, you must strictly follow the REQUIREMENTS \\\n",
        "\n",
        "REQUIREMENTS:\n",
        "1. The CONTEXT provided to you is the news transcript data and our end goal is to understand the entire news transcript \\\n",
        "2. You must generate 4 detailed conversational question-answer pairs using the information of CONTEXT \\\n",
        "3. The conversational questions and answers should not mention the presence of the CONTEXT, The CONTEXT is just an information bank \\\n",
        "4. The question needs to be concise and clear covering What, How, Why, all kind of questions from the CONTEXT. The Q&A pairs needs to be created for every 3-4 sentences \\\n",
        "5. For the generated question, refer to the CONTEXT and generate reported based conversational descriptive answer in detail. The Answer should be the most descriptive \\\n",
        "6. Make the answer to the point, more specific and relevant to question context, dont give boring and irrelevant answers \\\n",
        "7. Generated conversational questions-answer pairs for the given CONTEXT should cover the most of the CONTEXT without any repitition \\\n",
        "8. Generate Question & Answer pairs in such a manner that they are asked by someone who does not know about the CONTEXT. The CONTEXT is just a source of knowledge\\\n",
        "9. The goal is to mimic an engaging conversations between individuals eager to explore the paragraph's subject matter in detail \\\n",
        "10. You should strictly follow the Output format.\n",
        "{\n",
        "  \"questions\": [\n",
        "    {\n",
        "      \"question\": \"<generated-question>\",\n",
        "      \"answer\": \"<generated-answer>\"\n",
        "    },\n",
        "    ...\n",
        "  ]\n",
        "}\n",
        "If you fail to meet the requirements, you are fired \\\n",
        "\n",
        "CONTEXT: {context}\n",
        "Return in JSON as per Output format. Directly give in json format {}, don't include additional text \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "DD4o2pXD9sU2",
        "outputId": "8c32c1fa-3c57-4f5d-81cb-21da4ca293d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41518\n",
            "4151\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'\\n  \"questions\"'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-dec38e36479a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubstrings\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdivide_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstrings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '\\n  \"questions\"'"
          ]
        }
      ],
      "source": [
        "substrings  = divide_string(ds[1]['context'])\n",
        "temp = template.format(substrings[0])\n",
        "temp\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V--52L1HNB9T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOOIzcRkxfecPB/gwTsk1yI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0674d524eb94868aca3ef1bfa97284c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60fc1f72f9d84934b9ad7a1300837626",
              "IPY_MODEL_8cd4315cb8924e5db6f45697f3d589d0",
              "IPY_MODEL_c1dbdc045f874d71a6bdb7f9524e8fa3"
            ],
            "layout": "IPY_MODEL_ef36abd2b2b74ba59dd3c857fadd5cdc"
          }
        },
        "60fc1f72f9d84934b9ad7a1300837626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a6875acb324409e9593eb3f2974f36b",
            "placeholder": "​",
            "style": "IPY_MODEL_69870aef330647c98072c185d6e2c9f6",
            "value": "README.md: 100%"
          }
        },
        "8cd4315cb8924e5db6f45697f3d589d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2866dc3ade624e0faffb22581c88ac73",
            "max": 324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5708368d24e54c798f05f68873055ed1",
            "value": 324
          }
        },
        "c1dbdc045f874d71a6bdb7f9524e8fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee19facb6a042109ee81d7c0a13cf93",
            "placeholder": "​",
            "style": "IPY_MODEL_1096e13b86804a9cafb3afa4342d08d0",
            "value": " 324/324 [00:00&lt;00:00, 23.6kB/s]"
          }
        },
        "ef36abd2b2b74ba59dd3c857fadd5cdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6875acb324409e9593eb3f2974f36b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69870aef330647c98072c185d6e2c9f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2866dc3ade624e0faffb22581c88ac73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5708368d24e54c798f05f68873055ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ee19facb6a042109ee81d7c0a13cf93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1096e13b86804a9cafb3afa4342d08d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d119e2bc08f4373a299468742dce172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28a02dd3df3946ee830d8dc4540c5fc8",
              "IPY_MODEL_1a3b3b3ce4ef4d20b2eb587320184dbb",
              "IPY_MODEL_17d2772d86f94695b94e29a0274e9826"
            ],
            "layout": "IPY_MODEL_1ca01acd7bdf4586bc0614a67b936847"
          }
        },
        "28a02dd3df3946ee830d8dc4540c5fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_537e573bd62e4b7b96853370d60ec48a",
            "placeholder": "​",
            "style": "IPY_MODEL_698dbcb270b44d4cae56ee05ef6d61cf",
            "value": "train-00000-of-00006.parquet: 100%"
          }
        },
        "1a3b3b3ce4ef4d20b2eb587320184dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7877f39b96c141fbb2aea6b6e724d515",
            "max": 261435788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86908cb003204c058873d3e5e6e7ef29",
            "value": 261435788
          }
        },
        "17d2772d86f94695b94e29a0274e9826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_474aecf520484bbab22ce1e5288bf993",
            "placeholder": "​",
            "style": "IPY_MODEL_8de01b7b56904392a1fe139fffcc2db4",
            "value": " 261M/261M [00:06&lt;00:00, 43.0MB/s]"
          }
        },
        "1ca01acd7bdf4586bc0614a67b936847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537e573bd62e4b7b96853370d60ec48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698dbcb270b44d4cae56ee05ef6d61cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7877f39b96c141fbb2aea6b6e724d515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86908cb003204c058873d3e5e6e7ef29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "474aecf520484bbab22ce1e5288bf993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8de01b7b56904392a1fe139fffcc2db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cb8be7bc5a94c58bc53c453475dbdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_922bec68502542d19fdb07c354013beb",
              "IPY_MODEL_f8a5f63d905b4a58b6e188a70746a6a9",
              "IPY_MODEL_3540853c6b5b4e118354c3c0586b9516"
            ],
            "layout": "IPY_MODEL_2199418ec51b4164923094c33dd65a02"
          }
        },
        "922bec68502542d19fdb07c354013beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e6cdd4b54344d20ba00e1f7866b7c3d",
            "placeholder": "​",
            "style": "IPY_MODEL_c3cfc585943e4169824477dc85e256e3",
            "value": "train-00001-of-00006.parquet: 100%"
          }
        },
        "f8a5f63d905b4a58b6e188a70746a6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f230f44def7b4f87bfa18d0f81c86378",
            "max": 253072812,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4231a0c0d3f473e97ac3f762a3030b0",
            "value": 253072812
          }
        },
        "3540853c6b5b4e118354c3c0586b9516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3562c0a156564caba3213b2aa2ab26ca",
            "placeholder": "​",
            "style": "IPY_MODEL_407a23a07d984ee0b4619ec865750ce2",
            "value": " 253M/253M [00:05&lt;00:00, 42.7MB/s]"
          }
        },
        "2199418ec51b4164923094c33dd65a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e6cdd4b54344d20ba00e1f7866b7c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cfc585943e4169824477dc85e256e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f230f44def7b4f87bfa18d0f81c86378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4231a0c0d3f473e97ac3f762a3030b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3562c0a156564caba3213b2aa2ab26ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "407a23a07d984ee0b4619ec865750ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "141464a4ff0c4f3aa76eae1fdddb46a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fce44f14cb734ecca3baca4154ae3398",
              "IPY_MODEL_18b27548ca0c447c88e7b62e7979d7e1",
              "IPY_MODEL_556224c796304c4f802617dbf8b2c8a0"
            ],
            "layout": "IPY_MODEL_4cd5441764b64d60b1d4301ce029f91a"
          }
        },
        "fce44f14cb734ecca3baca4154ae3398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd0dfc0b41a14dd285f8d2637358c72f",
            "placeholder": "​",
            "style": "IPY_MODEL_e1e05db9f46d41bf93d049e974ed172a",
            "value": "train-00002-of-00006.parquet: 100%"
          }
        },
        "18b27548ca0c447c88e7b62e7979d7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dbf105617be4a9f92f74ac764ee5f5d",
            "max": 250756764,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_537eea5ab7cc4e949a1a020b3d0ed94f",
            "value": 250756764
          }
        },
        "556224c796304c4f802617dbf8b2c8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a8cdb06435d4e3ab9e45dceb485d931",
            "placeholder": "​",
            "style": "IPY_MODEL_93ecf2676a1d496bb2d2cecc13f4a570",
            "value": " 251M/251M [00:05&lt;00:00, 42.9MB/s]"
          }
        },
        "4cd5441764b64d60b1d4301ce029f91a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd0dfc0b41a14dd285f8d2637358c72f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1e05db9f46d41bf93d049e974ed172a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dbf105617be4a9f92f74ac764ee5f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537eea5ab7cc4e949a1a020b3d0ed94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a8cdb06435d4e3ab9e45dceb485d931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ecf2676a1d496bb2d2cecc13f4a570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f4ec2cdc7284ab6b300431bd9dd01c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ea5d709311b4a99b15c1b294ebb2305",
              "IPY_MODEL_8dded18238864ba1b611ff50f0d6bdfe",
              "IPY_MODEL_8eb6986493cf401f8c8166e535260cca"
            ],
            "layout": "IPY_MODEL_da3ed1c2626649308cf19091b5f50088"
          }
        },
        "8ea5d709311b4a99b15c1b294ebb2305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34ee8aff4b20423abc89f8352683784a",
            "placeholder": "​",
            "style": "IPY_MODEL_eb88c03a22fa4798944d05a5d9995fe4",
            "value": "train-00003-of-00006.parquet: 100%"
          }
        },
        "8dded18238864ba1b611ff50f0d6bdfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40edf3ecafba4fe2b55e409b2009d517",
            "max": 252260300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3265ff5748ab4d728345c730118f3067",
            "value": 252260300
          }
        },
        "8eb6986493cf401f8c8166e535260cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fbad0ce5e3745b7a9915b2ac6dd0781",
            "placeholder": "​",
            "style": "IPY_MODEL_c08dfcb9e29343ea8c920e437d731042",
            "value": " 252M/252M [00:05&lt;00:00, 43.1MB/s]"
          }
        },
        "da3ed1c2626649308cf19091b5f50088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34ee8aff4b20423abc89f8352683784a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb88c03a22fa4798944d05a5d9995fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40edf3ecafba4fe2b55e409b2009d517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3265ff5748ab4d728345c730118f3067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fbad0ce5e3745b7a9915b2ac6dd0781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c08dfcb9e29343ea8c920e437d731042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab613d64c0ff4ac69b89084aa9b9704a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15cdda31143f4c64bd1c623e18d2ed58",
              "IPY_MODEL_28bd01a14c5d4a66a0c5e27d0b3d0af9",
              "IPY_MODEL_3ac1a64155ec4dc38b1ae8be408167e2"
            ],
            "layout": "IPY_MODEL_6820b7a53f46430a87b4d8d9c6abddb9"
          }
        },
        "15cdda31143f4c64bd1c623e18d2ed58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d74fc0962c04157b6001e0ae7f76161",
            "placeholder": "​",
            "style": "IPY_MODEL_f63122cd911041e6a970f58f6cd1c458",
            "value": "train-00004-of-00006.parquet: 100%"
          }
        },
        "28bd01a14c5d4a66a0c5e27d0b3d0af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_207363544cb946bfa246d7d890f6fa27",
            "max": 258688982,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce2e0c8864524dbc992b79b43d7c6c0f",
            "value": 258688982
          }
        },
        "3ac1a64155ec4dc38b1ae8be408167e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bf0fa8aab4143f6ae7dc3dd7a6ac620",
            "placeholder": "​",
            "style": "IPY_MODEL_f9b4dc7816854c299d7360a4f518b8b7",
            "value": " 259M/259M [00:06&lt;00:00, 42.6MB/s]"
          }
        },
        "6820b7a53f46430a87b4d8d9c6abddb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d74fc0962c04157b6001e0ae7f76161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f63122cd911041e6a970f58f6cd1c458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "207363544cb946bfa246d7d890f6fa27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce2e0c8864524dbc992b79b43d7c6c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bf0fa8aab4143f6ae7dc3dd7a6ac620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b4dc7816854c299d7360a4f518b8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9dac3c57879433fa097c31106226ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2caa1836bc2e42f68942d12311878406",
              "IPY_MODEL_5c20c5c578f34cc096bd83d80669e7fb",
              "IPY_MODEL_4920ffc9665d4058b821139bd4e3ec03"
            ],
            "layout": "IPY_MODEL_10f94446b9da4c2aaa1ace9e6d55c4da"
          }
        },
        "2caa1836bc2e42f68942d12311878406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e43f6d5d8e8243f0a430c5773b7a3091",
            "placeholder": "​",
            "style": "IPY_MODEL_9900435b269d41bb905537fd79968856",
            "value": "train-00005-of-00006.parquet: 100%"
          }
        },
        "5c20c5c578f34cc096bd83d80669e7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a89a5133a99a410aa9a5f8208d01d006",
            "max": 250573008,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65e44c2bed43456bb244b30f9e14d089",
            "value": 250573008
          }
        },
        "4920ffc9665d4058b821139bd4e3ec03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3501a4369824fe79efd062606012d87",
            "placeholder": "​",
            "style": "IPY_MODEL_a4d058f58dfe4f9cb08f023429944793",
            "value": " 251M/251M [00:05&lt;00:00, 42.9MB/s]"
          }
        },
        "10f94446b9da4c2aaa1ace9e6d55c4da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e43f6d5d8e8243f0a430c5773b7a3091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9900435b269d41bb905537fd79968856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a89a5133a99a410aa9a5f8208d01d006": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e44c2bed43456bb244b30f9e14d089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3501a4369824fe79efd062606012d87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d058f58dfe4f9cb08f023429944793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48c7318c932f427e87b3cb73e2e6d192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82214918f99945e9bbbcf963c30548f5",
              "IPY_MODEL_d9fc91cc653141288bc9d2e0b9cddc03",
              "IPY_MODEL_20706b6f758447a3ae9bcac6ba0f496d"
            ],
            "layout": "IPY_MODEL_1a29a7e0a4ea4aeca6737b1d4e63e5a5"
          }
        },
        "82214918f99945e9bbbcf963c30548f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a56c61300814b2b880d738dd0454ebc",
            "placeholder": "​",
            "style": "IPY_MODEL_9ac08ddb7e514a68b2a1bf948d261ed9",
            "value": "Generating train split: 100%"
          }
        },
        "d9fc91cc653141288bc9d2e0b9cddc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f9906f5e4c4775ab9b9c814a6a4423",
            "max": 68325,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd528336eeb2496da19d9de49020bb9e",
            "value": 68325
          }
        },
        "20706b6f758447a3ae9bcac6ba0f496d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f0ee538e7b43f9a9ac0211ce7a94ec",
            "placeholder": "​",
            "style": "IPY_MODEL_63f995713df140f3a32a257bac42a98f",
            "value": " 68325/68325 [00:23&lt;00:00, 3586.20 examples/s]"
          }
        },
        "1a29a7e0a4ea4aeca6737b1d4e63e5a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a56c61300814b2b880d738dd0454ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac08ddb7e514a68b2a1bf948d261ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9f9906f5e4c4775ab9b9c814a6a4423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd528336eeb2496da19d9de49020bb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44f0ee538e7b43f9a9ac0211ce7a94ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f995713df140f3a32a257bac42a98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}